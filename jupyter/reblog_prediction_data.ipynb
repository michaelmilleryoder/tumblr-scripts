{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_dirpath = '/usr2/mamille2/tumblr/data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See if can use data that already have for reblog prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load followers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5226750\n",
      "Index(['tumblog_id', 'activity_time_epoch', 'tumblr_blog_name',\n",
      "       'tumblr_blog_title', 'tumblr_blog_description', 'tumblr_blog_url',\n",
      "       'tumblr_blog_theme', 'is_group_blog', 'is_primary', 'is_private',\n",
      "       'created_time_epoch', 'updated_time_epoch', 'timezone', 'language',\n",
      "       'blog_classifier', 'generated_date', 'parsed_blog_description',\n",
      "       'age_terms', 'age', 'ethnicity/nationality_terms',\n",
      "       'ethnicity/nationality', 'fandoms_terms', 'fandoms', 'gender_terms',\n",
      "       'gender', 'gender/sexuality_terms', 'gender/sexuality',\n",
      "       'interests_terms', 'interests', 'location_terms', 'location',\n",
      "       'personality type_terms', 'personality type', 'pronouns_terms',\n",
      "       'pronouns', 'relationship status_terms', 'relationship status',\n",
      "       'roleplay_terms', 'roleplay', 'roleplay/fandoms_terms',\n",
      "       'roleplay/fandoms', 'sexual orientation_terms', 'sexual orientation',\n",
      "       'weight_terms', 'weight', 'ethnicity/nationality_hegemonic_present',\n",
      "       'gender_hegemonic_present', 'pronouns_hegemonic_present',\n",
      "       'sexual orientation_hegemonic_present',\n",
      "       'ethnicity/nationality_opposite_present', 'gender_opposite_present',\n",
      "       'pronouns_opposite_present', 'sexual orientation_opposite_present',\n",
      "       'gender/sexuality_opposite_present',\n",
      "       'gender/sexuality_hegemonic_present'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "follower_data = pd.read_pickle(os.path.join(data_dirpath, 'blog_descriptions_recent100.pkl'))\n",
    "print(len(follower_data))\n",
    "print(follower_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load followees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "Index(['tumblog_id', 'followed_tumblog_id', 'activity_time_epoch'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Test follow structure\n",
    "\n",
    "follow_fpath = '/usr2/kmaki/tumblr/follow_network.tsv' # 99G\n",
    "chunksize = int(1e5)\n",
    "hdr = ['tumblog_id', 'followed_tumblog_id', 'activity_time_epoch']\n",
    "chunked = pd.read_csv(follow_fpath, sep='\\t', header=None, names=hdr, iterator=True)\n",
    "follow_data = chunked.get_chunk(chunksize)\n",
    "print(len(follow_data))\n",
    "print(follow_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480e268fe4af47a49ade6769e73fe850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100861970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3044188"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what follow structure can find for set of followers\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import numpy as np\n",
    "\n",
    "follow_fpath = '/usr2/kmaki/tumblr/follow_network.tsv' # 99G\n",
    "chunksize = int(1e5)\n",
    "total_iters = int(np.ceil(3220088178 / chunksize))\n",
    "hdr = ['tumblog_id', 'followed_tumblog_id', 'activity_time_epoch']\n",
    "chunked = pd.read_csv(follow_fpath, sep='\\t', header=None, names=hdr, chunksize=chunksize)\n",
    "\n",
    "stx_follower_ids = set()\n",
    "# follower_ids = follower_data['tumblog_id'].tolist()\n",
    "# followee_data = []\n",
    "\n",
    "for chunk in tqdm(chunked, total=total_iters):\n",
    "    stx_follower_ids |= set(chunk['tumblog_id'].unique())\n",
    "#     followee_data.append(chunk[chunk['tumblog_id'].isin(follower_ids)].values)\n",
    "    \n",
    "    \n",
    "print(len(stx_follower_ids))\n",
    "\n",
    "follower_ids = stx_follower_ids.intersection(set(follower_data['tumblog_id']))\n",
    "len(follower_ids) # Have at least one piece of follow information for these users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out follower ids\n",
    "with open(os.path.join(data_dirpath, 'halfday_followers_with_descriptions.txt'), 'w') as f:\n",
    "    for i in sorted(follower_ids):\n",
    "        f.write(f'{i}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b82634060224071b21ecf40e8ace254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=32201), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-68b6442afc57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mfollowee_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'tumblog_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollower_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mfollower_follow_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfollowee_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhdr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(self, values)\u001b[0m\n\u001b[1;32m   2801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m         \"\"\"\n\u001b[0;32m-> 2803\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2804\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36misin\u001b[0;34m(comps, values)\u001b[0m\n\u001b[1;32m    433\u001b[0m             \u001b[0mcomps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0mcomps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int64'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismember_int64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get followee data\n",
    "follow_fpath = '/usr2/kmaki/tumblr/follow_network.tsv' # 99G\n",
    "chunksize = int(1e5)\n",
    "total_iters = int(np.ceil(3220088178 / chunksize))\n",
    "hdr = ['tumblog_id', 'followed_tumblog_id', 'activity_time_epoch']\n",
    "chunked = pd.read_csv(follow_fpath, sep='\\t', header=None, names=hdr, chunksize=chunksize)\n",
    "\n",
    "followee_data = [] # list of np arrays to be concatenated\n",
    "\n",
    "for chunk in tqdm(chunked, total=total_iters):\n",
    "    followee_data.append(chunk[chunk['tumblog_id'].isin(follower_ids)].values)\n",
    "    \n",
    "follower_follow_data = pd.DataFrame(np.vstack(followee_data), columns=hdr)\n",
    "len(follower_follow_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save follow data from followers for which have descriptions\n",
    "out_fname = 'follow_data_recent100.pkl'\n",
    "\n",
    "follower_follow_data.to_pickle(os.path.join(data_dirpath, out_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6361471"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For how many followees do we have blog descriptions for?\n",
    "followees = set(follower_follow_data['followed_tumblog_id'])\n",
    "print(len(followees))\n",
    "\n",
    "followees_with_descriptions = followees.intersection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_fname = 'textposts_recent100.pkl'\n",
    "post_data = pd.read_pickle(os.path.join(data_dirpath, post_fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

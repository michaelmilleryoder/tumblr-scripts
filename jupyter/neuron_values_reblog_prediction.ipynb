{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "\n",
    "data_dirpath = '/usr2/mamille2/tumblr/data/sample1k'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_path = os.path.join(data_dirpath, 'models', 'ffn_labels_baseline+exp1+exp2_all.pkl')\n",
    "with open(model_path, 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(641403, 17775)\n"
     ]
    }
   ],
   "source": [
    "data_fpath = os.path.join(data_dirpath, 'output', 'features', 'ffn_labels_baseline+exp1+exp2_all_features.pkl')\n",
    "with open(data_fpath, 'rb') as f:\n",
    "    X_train, y_train, X_test, y_test = pickle.load(f)\n",
    "    \n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass of data through weights, non-linearities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17775, 100)\n",
      "(100, 32)\n",
      "(32, 50)\n",
      "(50, 1)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.coefs_:\n",
    "    print(layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(32,)\n",
      "(50,)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "for layer in model.intercepts_:\n",
    "    print(layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return max(0,x)\n",
    "\n",
    "relu_vec = np.vectorize(relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "<class 'numpy.ndarray'>\n",
      "(641403, 32)\n",
      "\n",
      "2\n",
      "<class 'numpy.ndarray'>\n",
      "(641403, 50)\n",
      "\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "neuron_values = [] # flattened, should be 100 + 32 + 50 + 1\n",
    "    \n",
    "# Input to first layer\n",
    "neuron_values.append(relu_vec(csr_matrix.dot(X_train, model.coefs_[0]) + model.intercepts_[0]))\n",
    "\n",
    "for i in range(1, len(model.coefs_)-1):\n",
    "    print(i)\n",
    "    layer_values = relu_vec(np.dot(neuron_values[i-1], model.coefs_[i]) + model.intercepts_[i])\n",
    "    neuron_values.append(layer_values)\n",
    "    print(type(layer_values))\n",
    "    print(layer_values.shape)\n",
    "    print()\n",
    "    \n",
    "print(len(neuron_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(641403, 182)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten into a table\n",
    "neuron_values_arr = np.hstack(neuron_values)\n",
    "neuron_values_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save out table\n",
    "np.save(os.path.join(data_dirpath, 'neural_pathways', 'ffn_labels_baseline+exp1+exp2_pathways.npy'), neuron_values_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions, actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "641403"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save gold\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(os.path.join(data_dirpath, 'output', 'predictions', 'ffn_labels_baseline+exp1+exp2_train_actual.txt'), y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear probes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follower ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "641403\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_dirpath = '/usr2/mamille2/tumblr/data/sample1k'\n",
    "\n",
    "# Load feature info\n",
    "feature_fpath = os.path.join(data_dirpath, 'feature_tables', 'reblog_features.csv')\n",
    "features = pd.read_csv(feature_fpath)\n",
    "\n",
    "train, test = train_test_split(features, test_size=0.1, random_state=12345)\n",
    "\n",
    "print(len(train['tumblog_id_follower']))\n",
    "\n",
    "train.loc[:, ['tumblog_id_follower']].to_csv(os.path.join(data_dirpath, 'output', \n",
    "                                                            'features', 'ffn_labels_baseline+exp1+exp2_follower_ids.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

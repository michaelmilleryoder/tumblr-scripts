{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "data_dirpath = '/usr2/mamille2/tumblr/data/sample1k'\n",
    "\n",
    "feature_tables_dir = os.path.join(data_dirpath, 'feature_tables')\n",
    "filenames = ['reblog_features.csv', 'nonreblog_features.csv', 'ranking_labels.csv']\n",
    "joined_filenames = [os.path.join(feature_tables_dir, filename) for filename in filenames]\n",
    "# csv_readers = [csv.DictReader(codecs.open(filename, 'rU', 'utf-16')) for filename in joined_filenames]\n",
    "csv_readers = [csv.DictReader(x.replace('\\0', '') for x in open(filename, 'r')) for filename in joined_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712670 712670\n"
     ]
    }
   ],
   "source": [
    "instances = []\n",
    "instance_labels = []\n",
    "for row in zip(*csv_readers):\n",
    "    reblog_features = row[0]\n",
    "    nonreblog_features = row[1]\n",
    "    label = int(row[2]['ranking_label'])\n",
    "    instance = (reblog_features, nonreblog_features)\n",
    "    instances.append(instance)\n",
    "    instance_labels.append(label)\n",
    "    \n",
    "print(len(instances), len(instance_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tag vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14318\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def _str2list(in_str):\n",
    "    return [el[1:-1] for el in in_str[1:-1].split(', ')]\n",
    "\n",
    "def update_tag_counts(tag_counts, counted_ids, candidate): # for hashtags\n",
    "#     candidate_tags = [tag.lower() for tag in eval(candidate['post_tags'])] # uses tokens provided in feature tables\n",
    "    candidate_tags = [tag.lower() for tag in _str2list(candidate['post_tags'])] # uses tokens provided in feature tables\n",
    "    followee_id = candidate['tumblog_id_followee']    \n",
    "    for tag in candidate_tags:\n",
    "        if not followee_id in counted_ids[tag]: # only counts the tag if user hasn't already used the tag\n",
    "            tag_counts[tag] += 1\n",
    "            counted_ids[tag].add(followee_id)\n",
    "        \n",
    "counted_ids = defaultdict(lambda: set()) # for each tag, a set of followees who used those tags\n",
    "tag_counts = defaultdict(int) # count of unique followees who used each tag\n",
    "for reblog_candidate, nonreblog_candidate in instances:\n",
    "    update_tag_counts(tag_counts, counted_ids, reblog_candidate)\n",
    "    update_tag_counts(tag_counts, counted_ids, nonreblog_candidate)\n",
    "\n",
    "tag_counts_filtered = {k:v for k,v in tag_counts.items() if v > 1} # at least 2 users used the tag\n",
    "tag_vocab = tag_counts_filtered.keys()\n",
    "print(len(tag_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_categories = ['age', 'ethnicity/nationality', 'fandoms', 'gender',\n",
    "                       'interests', 'location', 'personality type', 'pronouns', 'relationship status', 'roleplay',\n",
    "                       'sexual orientation', 'weight', 'zodiac']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count category label instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_label_counts = defaultdict(lambda: defaultdict(int))\n",
    "counted_ids = set()\n",
    "for category in identity_categories:\n",
    "    counted_ids = set()\n",
    "    for reblog_candidate, nonreblog_candidate in instances:\n",
    "        category_followee = category + '_terms_followee'\n",
    "        followee_id = reblog_candidate['tumblog_id_followee']\n",
    "        if not followee_id in counted_ids:\n",
    "            category_value = [x.lower() for x in eval(reblog_candidate[category_followee])]\n",
    "            for value in category_value:\n",
    "                category_label_counts[category][value] += 1\n",
    "            counted_ids.add(followee_id)\n",
    "            \n",
    "        followee_id = nonreblog_candidate['tumblog_id_followee']\n",
    "        if not followee_id in counted_ids:\n",
    "            category_value = [x.lower() for x in eval(nonreblog_candidate[category_followee])]\n",
    "            for value in category_value:\n",
    "                category_label_counts[category][value] += 1\n",
    "            counted_ids.add(followee_id)\n",
    "        \n",
    "        category_follower = category + '_terms_follower'\n",
    "        follower_id = reblog_candidate['tumblog_id_follower']\n",
    "        if not follower_id in counted_ids:\n",
    "            category_value = [x.lower() for x in eval(reblog_candidate[category_follower])]\n",
    "            for value in category_value:\n",
    "                category_label_counts[category][value] += 1\n",
    "            counted_ids.add(follower_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create category label vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age 65\n",
      "{'56', 'xxiv', 'nineteen', 'y/o', '28', '29', '58', 'age', '24', 'eighteen', '44', '25', '21', '46', 'xix', '18', '26', '17', '33', 'seventeen', '52', 'forty', 'fourteen', 'fifteen', '36', '42', '43', '16', '14', '23', '20', 'sixteen', '48', '11', '32', '15', '31', '55', '59', 'xxix', '13', '30', '22', '54', '12', '45', '35', '37', '47', '57', 'twelve', '19', '38', '49', 'fifty', '10', '27', '53', '51', '40', '39', '41', '50', '34', 'twenty'}\n",
      "-----------------\n",
      "\n",
      "ethnicity/nationality 81\n",
      "{'black', 'thai', 'haitian', 'turkish', 'malay', 'papel', 'austrian', 'colombian', 'norwegian', 'japanese', 'european', 'turks', 'dakota', 'lithuanian', 'ottawa', 'thais', 'scandinavian', 'portuguese', 'romanian', 'south african', 'polish', 'saudi', 'italian', 'hungarian', 'filipina', 'canadian', 'scottish', 'puerto', 'moroccan', 'african', 'english', 'spanish', 'french', 'chilena', 'american', 'swedish', 'latino', 'swede', 'coeur', 'singaporean', 'czech', 'dominican', 'mexican', 'serbian', 'pakistani', 'german', 'belgian', 'finnish', 'omaha', 'danish', 'southern', 'tigre', 'chilean', 'venezuelan', 'brazilian', 'chinese', 'asian', 'filipino', 'indian', 'chileno', 'cuban', 'irish', 'korean', 'dutch', 'indonesian', 'white', 'greek', 'mexicano', 'jamaican', 'americans', 'swiss', 'hispanic', 'latina', 'malaysian', 'armenian', 'russian', 'vietnamese', 'australian', 'mexicana', 'british', 'albanian'}\n",
      "-----------------\n",
      "\n",
      "fandoms 54\n",
      "{'rey', 'kpop', 'got7', 'yuri', 'twd', 'reylo', 'hamilton', 'star wars', 'fanatic', 'verse', 'ships', 'fandom', 'universe', 'shaladin', 'stan', 'canon', 'k-pop', 'yaoi', 'harry potter', 'hogwarts', 'army', 'mcu', 'comic', 'multi-fandom', 'potterhead', 'ereri', 'hp', 'multiverse', 'homestuck', 'overwatch', 'swiftie', 'supercorp', 'undertale', 'multiship', 'riverdale', 'otaku', 'tjlc', 'series', 'sims', 'shipper', 'wwe', 'multi-ship', 'marvel', 'fan', 'voltron', 'i ship', 'sherlock', '5sos', 'exo', 'pokemon', 'phan', 'bts', 'disney', 'bnha'}\n",
      "-----------------\n",
      "\n",
      "gender 33\n",
      "{'cis', 'mom', 'mommy', 'androgynous', 'lgbt', 'genderfluid', 'daughter', 'husband', 'mtf', 'dad', 'queen', 'agender', 'boy', 'guy', 'gurl', 'woman', 'ftm', 'princess', 'nonbinary', 'trans', 'female', 'nb', 'lady', 'non-binary', 'man', 'sister', 'wife', 'bigender', 'girl', 'mum', 'son', 'male', 'brother'}\n",
      "-----------------\n",
      "\n",
      "interests 71\n",
      "{'manga', 'family', 'aesthetics', 'lifestyle', 'dog', 'pizza', 'photos', 'memes', 'reading', 'robot', 'write', 'poetry', 'tea', 'fitness', 'bands', 'comics', 'book', 'travel', 'design', 'books', 'gifs', 'fashion', 'games', 'dogs', 'hockey', 'hunting', 'metal', 'stuff', 'piano', 'weed', 'history', 'cat', 'music', 'art', 'writing', 'animal', 'hair', 'science', 'interests', 'cosplay', 'film', 'horror', 'anime', 'tv', 'meme', 'soccer', 'draw', 'clarinet', 'tattoos', 'things', 'desserts', 'nutrition', 'aesthetic', 'running', 'law', 'food', 'psychology', 'movies', 'photography', 'pies', 'meche', 'makeup', 'cats', 'theatre', 'drawing', 'nature', 'landscapes', 'gaming', 'animals', 'arts', 'coffee'}\n",
      "-----------------\n",
      "\n",
      "location 146\n",
      "{'ny', 'east', 'north', 'philadelphia', 'hawaii', 'croatia', 'tampa', 'nz', 'new zealand', 'mississippi', 'az', 'california', 'slovakia', 'taiwan', 'jamaica', 'texas', 'iÌ‡stanbul', 'illinois', 'philly', 'malaysia', 'athens', 'louisiana', 'fl', 'new hampshire', 'u.s', 'brazil', 'ohio', 'missouri', 'pnw', 'romania', 'florida', 'ca', 'slovenia', 'atlanta', 'socal', 'kentucky', 'ecuador', 'aus', 'mx', 'georgia', 'toronto', 'uk', 'argentina', 'rhode island', 'london', 'belgium', 'colorado', 'atl', 'pennsylvania', 'massachusetts', 'netherlands', 'arkansas', 'u.k', 'pa', 'iceland', 'thailand', 'virginia', 'australia', 'chicago', 'hong kong', 'poland', 'turkey', 'wisconsin', 'new york', 'india', 'alabama', 'serbia', 'greece', 'austria', 'south carolina', 'vietnam', 'germany', 'indonesia', 'montana', 'venezuela', 'kansas', 'new jersey', 'tx', 'umass', 'al', 'alaska', 'utah', 'maine', 'nj', 'berlin', 'cleveland', 'philippines', 'indiana', 'nc', 'egypt', 'chad', 'china', 'delaware', 'dc', 'bulgaria', 'maryland', 'tennessee', 'guinea', 'norway', 'north carolina', 'iowa', 'switzerland', 'washington', 'finland', 'singapore', 'hungary', 'south', 'israel', 'minnesota', 'mexico', 'albania', 'san', 'cali', 'canada', 'denmark', 'south africa', 'mÃ©xico', 'ireland', 'mali', 'west', 'united states', 'istanbul', 'japan', 'sweden', 'wa', 'midwest', 'jordan', 'oregon', 'france', 'michigan', 'madagascar', 'ct', 'nyc', 'italy', 'czech republic', 'colombia', 'arizona', 'va', 'portugal', 'spain', 'costa rica', 'u.s.', 'usa', 'oklahoma', 'chile', 'ga'}\n",
      "-----------------\n",
      "\n",
      "personality type 29\n",
      "{'lawful', 'extrovert', 'neutral', 'ambivert', 'istj', 'isfj', '4w5', 'infp', 'isfp', 'intp', 'introvert', 'istp', 'intj', 'entj', 'esfj', 'hufflepuff', 'enfp', '5w6', 'antp', 'infj', 'esfp', 'chaotic', 'entp', 'slytherin', 'gryffindor', 'enfj', '5w4', 'estp', 'ravenclaw'}\n",
      "-----------------\n",
      "\n",
      "pronouns 9\n",
      "{'pronouns', 'he', 'xe', 'them', 'her', 'him', 'they', 'she', 'itits'}\n",
      "-----------------\n",
      "\n",
      "relationship status 9\n",
      "{'wife', 'taken', 'single', 'spouse', 'engaged', 'married', 'couple', 'in a relationship', 'husband'}\n",
      "-----------------\n",
      "\n",
      "roleplay 7\n",
      "{'oc', 'm!a', 'rp', 'semi-selective', 'muse', 'roleplay', 'selective'}\n",
      "-----------------\n",
      "\n",
      "sexual orientation 18\n",
      "{'aro/ace', 'pansexual', 'queer', 'cishet', 'demisexual', 'lesbian', 'homo', 'mlm', 'wlw', 'gay', 'asexual', 'ace', 'pan', 'bi', 'aro-ace', 'straight', 'bisexual', 'lgbt'}\n",
      "-----------------\n",
      "\n",
      "weight 21\n",
      "{'bulimia', 'gw', 'eating disorder', 'hw', 'pounds', 'lbs', 'gw1', 'cw', 'weight', 'eating disorders', 'gw2', 'anorexia', 'lb', 'fat', 'lw', 'kg', 'ana', 'gw3', 'thin', 'anorexic', 'sw'}\n",
      "-----------------\n",
      "\n",
      "zodiac 7\n",
      "{'taurus', 'gemini', 'libra', 'leo', 'virgo', 'cancer', 'aries'}\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_vocabs = defaultdict(lambda: set())\n",
    "for identity_category in category_label_counts:\n",
    "    category_labels_filtered_vocab = set([k for k,v in category_label_counts[identity_category].items() if v > 1]) # min 2 users using label\n",
    "    category_vocabs[identity_category] = category_labels_filtered_vocab\n",
    "    print(identity_category, len(category_vocabs[identity_category]))\n",
    "    print(category_vocabs[identity_category])\n",
    "    print('-----------------')\n",
    "    print()\n",
    "    \"\"\"\n",
    "    sorted_category_labels = sorted(category_label_filtered[category].items(), key=lambda x: x[1], reverse=True)    \n",
    "    print(category)\n",
    "    print('-----------------')\n",
    "    for i in range(1, 21):\n",
    "        if i == len(sorted_category_labels):\n",
    "            break\n",
    "        print(sorted_category_labels[i][0], sorted_category_labels[i][1])\n",
    "    print('-----------------')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_post_baseline(reblog_candidate, nonreblog_candidate, label):\n",
    "    features = defaultdict(float)\n",
    "    # Comparison space features\n",
    "    def _extract_features_post_baseline_candidate(candidate, incr):\n",
    "        candidate_tags = [tag.lower() for tag in eval(candidate['post_tags'])]\n",
    "        for tag in candidate_tags:\n",
    "            if tag.lower() in tag_vocab:\n",
    "                feat_tag = ('tag=%s' % tag.lower())\n",
    "                features[feat_tag] += incr\n",
    "\n",
    "        post_type = candidate['post_type']\n",
    "        feat_tag = ('post_type=%s' % post_type)\n",
    "        features[feat_tag] += incr\n",
    "        \n",
    "        post_note_count = float(candidate['post_note_count'])\n",
    "        features['post_note_count'] += incr * post_note_count\n",
    "\n",
    "    if label == 1:\n",
    "        _extract_features_post_baseline_candidate(nonreblog_candidate, incr=-1)\n",
    "        _extract_features_post_baseline_candidate(reblog_candidate, incr=1)\n",
    "    else:\n",
    "        _extract_features_post_baseline_candidate(reblog_candidate, incr=-1)\n",
    "        _extract_features_post_baseline_candidate(nonreblog_candidate, incr=1)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Identity framing, presence of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_experiment_1(reblog_candidate, nonreblog_candidate, label):\n",
    "    # Baseline features\n",
    "    #features = defaultdict(float)\n",
    "    features = extract_features_post_baseline(reblog_candidate, nonreblog_candidate, label)\n",
    "    \n",
    "    # Follower features\n",
    "    for identity_category in identity_categories:\n",
    "        identity_category_follower = eval(reblog_candidate[identity_category + '_terms_follower'])\n",
    "        follower_presence = len(identity_category_follower) > 0\n",
    "        if follower_presence:\n",
    "            feat_tag = ('follower_cat=%s' % identity_category)\n",
    "            features[feat_tag] += 1\n",
    "            \n",
    "    # Comparison space features\n",
    "    def _extract_features_experiment_1_candidate(candidate, incr):\n",
    "        for identity_category in identity_categories:\n",
    "            identity_category_follower = eval(reblog_candidate[identity_category + '_terms_follower'])\n",
    "            follower_presence = len(identity_category_follower) > 0\n",
    "            identity_category_followee = eval(candidate[identity_category + '_terms_followee'])\n",
    "            followee_presence = len(identity_category_followee) > 0\n",
    "            if followee_presence:\n",
    "                feat_tag = ('followee_cat=%s' % identity_category)\n",
    "                features[feat_tag] += incr\n",
    "\n",
    "            # Alignment features\n",
    "            if ((follower_presence and followee_presence) or\n",
    "                (not follower_presence and not followee_presence)):\n",
    "                feat_tag = ('aligned_cat=%s' % identity_category)\n",
    "                features[feat_tag] += incr\n",
    "                \n",
    "    if label == 1:\n",
    "        _extract_features_experiment_1_candidate(nonreblog_candidate, incr=-1)\n",
    "        _extract_features_experiment_1_candidate(reblog_candidate, incr=1)\n",
    "    else:\n",
    "        _extract_features_experiment_1_candidate(reblog_candidate, incr=-1)\n",
    "        _extract_features_experiment_1_candidate(nonreblog_candidate, incr=1)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_experiment_2(reblog_candidate, nonreblog_candidate, label):\n",
    "    # Baseline features\n",
    "    #features = defaultdict(float)\n",
    "    #features = extract_features_post_baseline(reblog_candidate, nonreblog_candidate, label)\n",
    "    features = extract_features_experiment_1(reblog_candidate, nonreblog_candidate, label)\n",
    "\n",
    "    \n",
    "    # Follower features\n",
    "    for identity_category in identity_categories:\n",
    "        identity_category_follower = [x.lower() for x in eval(reblog_candidate[identity_category + '_terms_follower'])]\n",
    "        for identity_label in identity_category_follower:\n",
    "            if identity_label in category_vocabs[identity_category]:\n",
    "                feat_tag = ('cat=%s,follower_lab=%s' % (identity_category, identity_label))\n",
    "                features[feat_tag] += 1\n",
    "            \n",
    "    # Comparison space features\n",
    "    def _extract_features_experiment_2_candidate(candidate, incr):\n",
    "        for identity_category in identity_categories:\n",
    "            identity_category_follower = [x.lower() for x in eval(reblog_candidate[identity_category + '_terms_follower'])]\n",
    "            identity_category_followee = [x.lower() for x in eval(reblog_candidate[identity_category + '_terms_followee'])]\n",
    "            for identity_label_followee in identity_category_followee:\n",
    "                if identity_label_followee in category_vocabs[identity_category]:\n",
    "                    feat_tag = ('cat=%s,followee_lab=%s' % (identity_category, identity_label_followee))\n",
    "                    features[feat_tag] += incr\n",
    "                    \n",
    "                    # Compatibility features\n",
    "                    for identity_label_follower in identity_category_follower:\n",
    "                        if identity_label_follower in category_vocabs[identity_category]:\n",
    "                            feat_tag = ('cat=%s,follower_lab=%s,followee_lab=%s' % (identity_category,\n",
    "                                                                                    identity_label_follower,\n",
    "                                                                                    identity_label_followee))\n",
    "                            features[feat_tag] += incr\n",
    "            \n",
    "                \n",
    "    if label == 1:\n",
    "        _extract_features_experiment_2_candidate(nonreblog_candidate, incr=-1)\n",
    "        _extract_features_experiment_2_candidate(reblog_candidate, incr=1)\n",
    "    else:\n",
    "        _extract_features_experiment_2_candidate(reblog_candidate, incr=-1)\n",
    "        _extract_features_experiment_2_candidate(nonreblog_candidate, incr=1)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn import neural_network\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total= 8.8min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total= 9.9min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=10.3min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=14.1min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=14.4min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=15.0min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 6.3min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=15.7min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=15.7min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 6.2min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=16.8min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 4.0min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 9.2min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 7.6min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=23.7min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total= 7.2min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total=11.4min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total=16.5min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total=15.2min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total=17.4min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total= 9.1min\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed: 32.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV] .................................. C=1, penalty=l2, total= 5.4min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total=20.9min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total=10.8min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total=14.7min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total= 7.8min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total=26.1min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 9.1min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total=30.1min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 8.3min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total=10.1min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 7.3min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 9.9min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 9.3min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total=14.5min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total=21.7min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total=22.9min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total=18.1min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total=10.4min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total= 7.9min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total=13.8min\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total=12.3min\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total=11.0min\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total=13.6min\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total=10.9min\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total=10.7min\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total=12.1min\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total=16.7min\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total=18.1min\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total=18.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  50 out of  50 | elapsed: 73.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]0.626362832728\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for (reblog_candidate, nonreblog_candidate), label in zip(instances, instance_labels):\n",
    "    X.append(extract_features_post_baseline(reblog_candidate, nonreblog_candidate, label))\n",
    "    y.append(label)\n",
    "    \n",
    "post_features_vectorizer = feature_extraction.DictVectorizer()\n",
    "post_features_scaler = preprocessing.StandardScaler(with_mean=False)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=12345)\n",
    "X_train = post_features_vectorizer.fit_transform(X_train)\n",
    "X_train = post_features_scaler.fit_transform(X_train)\n",
    "X_test = post_features_vectorizer.transform(X_test)\n",
    "X_test = post_features_scaler.transform(X_test)\n",
    "\n",
    "model_base = svm.LinearSVC(dual=False, max_iter=10000, verbose=2)\n",
    "# parameters = {'C':[.1, 1, 10], 'penalty':['l1', 'l2']}\n",
    "parameters = {'C':[.01, .1, 1, 10, 100], 'penalty':['l2']}\n",
    "baseline_model = model_selection.GridSearchCV(model_base, parameters, n_jobs=5, cv=10, verbose=2).fit(X_train, y_train)\n",
    "print(baseline_model.score(X_test, y_test))\n",
    "baseline_pred = baseline_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Identity framing, presence of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total= 8.1min\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=11.1min\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=11.6min\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=12.5min\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=15.3min\n",
      "[CV] C=0.01, penalty=l2 ..............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total= 8.1min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total= 9.9min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=10.7min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=13.1min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ............................... C=0.01, penalty=l2, total=10.9min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total=10.5min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 9.8min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 7.6min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 7.3min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 5.1min\n",
      "[CV] C=0.1, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total=15.4min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total=16.3min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 8.8min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total= 6.2min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total= 8.1min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total= 4.7min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] ................................ C=0.1, penalty=l2, total=15.7min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total=10.4min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total= 9.6min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total=11.4min\n",
      "[CV] C=1, penalty=l2 .................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total= 5.2min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total= 5.8min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total= 7.2min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 8.2min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total=10.0min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] .................................. C=1, penalty=l2, total=11.5min\n",
      "[CV] C=10, penalty=l2 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed: 65.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][CV] .................................. C=1, penalty=l2, total=15.7min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total=12.0min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 6.5min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 7.3min\n",
      "[CV] C=10, penalty=l2 ................................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 5.1min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total=11.7min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................ C=100, penalty=l2, total= 6.7min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 7.5min\n",
      "[CV] C=100, penalty=l2 ...............................................\n",
      "[LibLinear][CV] ................................. C=10, penalty=l2, total= 9.1min\n",
      "[CV] C=100, penalty=l2 ...............................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a47afcacb3ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_scaler_experiment_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mexperiment_1_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_base\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_1_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mexperiment_1_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment_1_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    636\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    637\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 638\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for (reblog_candidate, nonreblog_candidate), label in zip(instances, instance_labels):\n",
    "    X.append(extract_features_experiment_1(reblog_candidate, nonreblog_candidate, label))\n",
    "    y.append(label)\n",
    "    \n",
    "features_vectorizer_experiment_1 = feature_extraction.DictVectorizer()\n",
    "features_scaler_experiment_1 = preprocessing.StandardScaler(with_mean=False)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=12345)\n",
    "X_train = features_vectorizer_experiment_1.fit_transform(X_train)\n",
    "X_train = features_scaler_experiment_1.fit_transform(X_train)\n",
    "X_test = features_vectorizer_experiment_1.transform(X_test)\n",
    "X_test = features_scaler_experiment_1.transform(X_test)\n",
    "\n",
    "experiment_1_model = model_selection.GridSearchCV(model_base, parameters, n_jobs=5, cv=10, verbose=2).fit(X_train, y_train)\n",
    "print(experiment_1_model.score(X_test, y_test))\n",
    "experiment_1_pred = experiment_1_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for (reblog_candidate, nonreblog_candidate), label in zip(instances, instance_labels):\n",
    "    X.append(extract_features_experiment_2(reblog_candidate, nonreblog_candidate, label))\n",
    "    y.append(label)\n",
    "    \n",
    "features_vectorizer_experiment_2 = feature_extraction.DictVectorizer()\n",
    "features_scaler_experiment_2 = preprocessing.StandardScaler(with_mean=False)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=12345)\n",
    "X_train = features_vectorizer_experiment_2.fit_transform(X_train)\n",
    "X_train = features_scaler_experiment_2.fit_transform(X_train)\n",
    "X_test = features_vectorizer_experiment_2.transform(X_test)\n",
    "X_test = features_scaler_experiment_2.transform(X_test)\n",
    "\n",
    "experiment_2_model = model_selection.GridSearchCV(model_base, parameters, cv=10).fit(X_train, y_train)\n",
    "print(experiment_2_model.score(X_test, y_test))\n",
    "experiment_2_pred = experiment_2_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McNemar's Test (Significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 0\n",
    "b = 0 # Baseline correct, experiment incorrect\n",
    "c = 0 # Baseline incorrect, experiment correct\n",
    "d = 0\n",
    "for b_pred, ex_pred, true in zip(baseline_pred, experiment_1_pred, y_test):\n",
    "    if b_pred == true and ex_pred == true:\n",
    "        a += 1\n",
    "    elif b_pred == true and ex_pred != true:\n",
    "        b += 1\n",
    "    elif b_pred != true and ex_pred == true:\n",
    "        c += 1\n",
    "    else:\n",
    "        d += 1\n",
    "        \n",
    "table = [[a, b],\n",
    "         [c, d]]\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of calculating the mcnemar test\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "# calculate mcnemar test\n",
    "result = mcnemar(table, exact=False, correction=False)\n",
    "# summarize the finding\n",
    "print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n",
    "# interpret the p-value\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "\tprint('Same proportions of errors (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "# data_dirpath = '/usr2/mamille2/tumblr/data' # erebor\n",
    "data_dirpath = '/usr0/home/mamille2/erebor/tumblr/data' # misty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3M dataset, cost-sensitive classification with Logistic Regression class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20163\n",
      "['accepts_answers',\n",
      " 'activity_time_epoch_followee',\n",
      " 'activity_time_epoch_follower',\n",
      " 'activity_time_epoch_post',\n",
      " 'age_followee',\n",
      " 'age_follower',\n",
      " 'age_terms_followee',\n",
      " 'age_terms_follower',\n",
      " 'blog_classifier_followee',\n",
      " 'blog_classifier_follower',\n",
      " 'blog_classifier_post',\n",
      " 'body',\n",
      " 'created_time_epoch_followee',\n",
      " 'created_time_epoch_follower',\n",
      " 'created_time_epoch_post',\n",
      " 'ethnicity/nationality_followee',\n",
      " 'ethnicity/nationality_follower',\n",
      " 'ethnicity/nationality_hegemonic_present_followee',\n",
      " 'ethnicity/nationality_hegemonic_present_follower',\n",
      " 'ethnicity/nationality_opposite_present_followee',\n",
      " 'ethnicity/nationality_opposite_present_follower',\n",
      " 'ethnicity/nationality_terms_followee',\n",
      " 'ethnicity/nationality_terms_follower',\n",
      " 'fandoms_followee',\n",
      " 'fandoms_follower',\n",
      " 'fandoms_terms_followee',\n",
      " 'fandoms_terms_follower',\n",
      " 'follower',\n",
      " 'gender/sexuality_followee',\n",
      " 'gender/sexuality_follower',\n",
      " 'gender/sexuality_hegemonic_present_followee',\n",
      " 'gender/sexuality_hegemonic_present_follower',\n",
      " 'gender/sexuality_opposite_present_followee',\n",
      " 'gender/sexuality_opposite_present_follower',\n",
      " 'gender/sexuality_terms_followee',\n",
      " 'gender/sexuality_terms_follower',\n",
      " 'gender_followee',\n",
      " 'gender_follower',\n",
      " 'gender_hegemonic_present_followee',\n",
      " 'gender_hegemonic_present_follower',\n",
      " 'gender_opposite_present_followee',\n",
      " 'gender_opposite_present_follower',\n",
      " 'gender_terms_followee',\n",
      " 'gender_terms_follower',\n",
      " 'generated_date_followee',\n",
      " 'generated_date_follower',\n",
      " 'interests_followee',\n",
      " 'interests_follower',\n",
      " 'interests_terms_followee',\n",
      " 'interests_terms_follower',\n",
      " 'is_group_blog_followee',\n",
      " 'is_group_blog_follower',\n",
      " 'is_primary_followee',\n",
      " 'is_primary_follower',\n",
      " 'is_private_followee',\n",
      " 'is_private_follower',\n",
      " 'is_submission',\n",
      " 'language_followee',\n",
      " 'language_follower',\n",
      " 'location_followee',\n",
      " 'location_follower',\n",
      " 'location_terms_followee',\n",
      " 'location_terms_follower',\n",
      " 'mentions',\n",
      " 'parsed_blog_description_followee',\n",
      " 'parsed_blog_description_follower',\n",
      " 'parsed_tags_minfreq1',\n",
      " 'personality type_terms_x',\n",
      " 'personality type_terms_y',\n",
      " 'personality type_x',\n",
      " 'personality type_y',\n",
      " 'post_caption',\n",
      " 'post_classifier',\n",
      " 'post_format',\n",
      " 'post_id',\n",
      " 'post_note_count',\n",
      " 'post_short_url',\n",
      " 'post_tags',\n",
      " 'post_text',\n",
      " 'post_title',\n",
      " 'post_type',\n",
      " 'pronouns_followee',\n",
      " 'pronouns_follower',\n",
      " 'pronouns_hegemonic_present_followee',\n",
      " 'pronouns_hegemonic_present_follower',\n",
      " 'pronouns_opposite_present_followee',\n",
      " 'pronouns_opposite_present_follower',\n",
      " 'pronouns_terms_followee',\n",
      " 'pronouns_terms_follower',\n",
      " 'reblogged',\n",
      " 'reblogged_from_metadata',\n",
      " 'reblogged_from_post_id',\n",
      " 'relationship status_terms_x',\n",
      " 'relationship status_terms_y',\n",
      " 'relationship status_x',\n",
      " 'relationship status_y',\n",
      " 'roleplay/fandoms_followee',\n",
      " 'roleplay/fandoms_follower',\n",
      " 'roleplay/fandoms_terms_followee',\n",
      " 'roleplay/fandoms_terms_follower',\n",
      " 'roleplay_followee',\n",
      " 'roleplay_follower',\n",
      " 'roleplay_terms_followee',\n",
      " 'roleplay_terms_follower',\n",
      " 'root_post_id',\n",
      " 'sexual_orientation_followee',\n",
      " 'sexual_orientation_follower',\n",
      " 'sexual_orientation_hegemonic_present_followee',\n",
      " 'sexual_orientation_hegemonic_present_follower',\n",
      " 'sexual_orientation_opposite_present_followee',\n",
      " 'sexual_orientation_opposite_present_follower',\n",
      " 'sexual_orientation_terms_followee',\n",
      " 'sexual_orientation_terms_follower',\n",
      " 'source_title',\n",
      " 'source_url',\n",
      " 'timezone_followee',\n",
      " 'timezone_follower',\n",
      " 'tumblog_id_followee',\n",
      " 'tumblog_id_follower',\n",
      " 'tumblr_blog_description_followee',\n",
      " 'tumblr_blog_description_follower',\n",
      " 'tumblr_blog_name_followee',\n",
      " 'tumblr_blog_name_follower',\n",
      " 'tumblr_blog_theme_followee',\n",
      " 'tumblr_blog_theme_follower',\n",
      " 'tumblr_blog_title_followee',\n",
      " 'tumblr_blog_title_follower',\n",
      " 'tumblr_blog_url_followee',\n",
      " 'tumblr_blog_url_follower',\n",
      " 'updated_time_epoch_followee',\n",
      " 'updated_time_epoch_follower',\n",
      " 'updated_time_epoch_post',\n",
      " 'weight_followee',\n",
      " 'weight_follower',\n",
      " 'weight_terms_followee',\n",
      " 'weight_terms_follower']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Load data\n",
    "# data = pd.read_pickle(os.path.join(data_dirpath, 'posts_descs_3m_rebloggers.pkl'))\n",
    "data = pd.read_pickle(os.path.join(data_dirpath, 'posts_descs_3m_reblog_restricted.pkl'))\n",
    "print(len(data))\n",
    "pprint(sorted(data.columns.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reblogged: 1824 / 16130 (11.308121512709238%)\n"
     ]
    }
   ],
   "source": [
    "# Split train/test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test = train_test_split(data, test_size=0.2, random_state=9)\n",
    "\n",
    "num_reblogs = len(data_train[data_train['reblogged']==True])\n",
    "print(f\"Reblogged: {num_reblogs} / {len(data_train)} ({num_reblogs/len(data_train) * 100}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decide features, vectorize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_vectorizer = CountVectorizer(min_df=1, max_features=50000, stop_words='english')\n",
    "text_vectorizer.fit(data_train['post_text']) # corpus is a list of strings (documents), probably can't fit to test\n",
    "\n",
    "feats = {'train':{}, 'test': {}}\n",
    "\n",
    "feats['train']['post_text'] = text_vectorizer.transform(data_train['post_text'])\n",
    "feats['test']['post_text'] = text_vectorizer.transform(data_test['post_text'])\n",
    "\n",
    "# desc_vectorizer = CountVectorizer(min_df=1, max_features=5000)\n",
    "# desc_vectorizer.fit(data_train['parsed_blog_description_followee']) # corpus is a list of strings (documents), probably can't fit to test\n",
    "# desc_vectorizer.fit(data_train['parsed_blog_description_follower']) # corpus is a list of strings (documents), probably can't fit to test\n",
    "\n",
    "# feats['train']['parsed_blog_description_followee'] = desc_vectorizer.transform(data_train['parsed_blog_description_followee'])\n",
    "# feats['test']['parsed_blog_description_followee'] = desc_vectorizer.transform(data_test['parsed_blog_description_followee'])\n",
    "# feats['train']['parsed_blog_description_follower'] = desc_vectorizer.transform(data_train['parsed_blog_description_follower'])\n",
    "# feats['test']['parsed_blog_description_follower'] = desc_vectorizer.transform(data_test['parsed_blog_description_follower'])\n",
    "\n",
    "len(feats['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16130, 50000)\n",
      "(4033, 50000)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train, X_test = hstack(list(feats['train'].values())), hstack(list(feats['test'].values()))\n",
    "y_train, y_test = data_train['reblogged'], data_test['reblogged']\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr0/home/mamille2/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='warn', n_jobs=None, penalty='l2', random_state=None,\n",
       "          solver='warn', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run logistic regression with class weighting\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# clf = LogisticRegression()\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "# clf = LogisticRegression(class_weight={0: 0.01, 1: 0.99})\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "734"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = clf.predict(X_test)\n",
    "sum(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Not reblogged</th>\n",
       "      <th>Reblogged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.900576</td>\n",
       "      <td>0.183924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.832213</td>\n",
       "      <td>0.291577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.865046</td>\n",
       "      <td>0.225564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Not reblogged  Reblogged\n",
       "Precision       0.900576   0.183924\n",
       "Recall          0.832213   0.291577\n",
       "F1              0.865046   0.225564"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = LogisticRegression(class_weight={0: 0.01, 1: 0.99})\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "scores = precision_recall_fscore_support(y_test, preds, average=None)\n",
    "\n",
    "scores_df = pd.DataFrame(np.array(scores[:-1]), columns=['Not reblogged', 'Reblogged'], \n",
    "                         index=['Precision', 'Recall', 'F1'])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save, load features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features\n",
    "import scipy.sparse\n",
    "\n",
    "scipy.sparse.save_npz(os.path.join(data_dirpath, 'bow_3m_post_desc_text_train_60k.npz'), X_train)\n",
    "scipy.sparse.save_npz(os.path.join(data_dirpath, 'bow_3m_post_desc_text_test_60k.npz'), X_test)\n",
    "# scipy.sparse.save_npz(os.path.join(data_dirpath, 'bow_3m_post_text_train_50k.npz'), X_train)\n",
    "# scipy.sparse.save_npz(os.path.join(data_dirpath, 'bow_3m_post_text_test_50k.npz'), X_test)\n",
    "# scipy.sparse.save_npz(os.path.join(data_dirpath, 'bow_3m_post_text_train.npz'), X_train)\n",
    "# scipy.sparse.save_npz(os.path.join(data_dirpath, 'bow_3m_post_text_test.npz'), X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save outcome measure\n",
    "import pickle\n",
    "with open(os.path.join(data_dirpath,'bow_3m_reblogged_train.pkl'), 'wb') as f:\n",
    "    pickle.dump(data_train['reblogged'], f)\n",
    "with open(os.path.join(data_dirpath, 'bow_3m_reblogged_test.pkl'), 'wb') as f:\n",
    "    pickle.dump(data_test['reblogged'], f)\n",
    "# scipy.sparse.save_npz(os.path.join(data_dirpath, 'bow_3m_reblogged_train.npz'), y_train)\n",
    "# scipy.sparse.save_npz(os.path.join(data_dirpath, 'bow_3m_reblogged_test.npz'), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2163083, 10000)\n",
      "(540771, 10000)\n",
      "(2163083,)\n",
      "(540771,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "import pickle\n",
    "import scipy.sparse\n",
    "\n",
    "X_train = scipy.sparse.load_npz(os.path.join(data_dirpath, 'bow_3m_post_text_train.npz'))\n",
    "X_test = scipy.sparse.load_npz(os.path.join(data_dirpath, 'bow_3m_post_text_test.npz'))\n",
    "\n",
    "with open(os.path.join(data_dirpath,'bow_3m_reblogged_train.pkl'), 'rb') as f:\n",
    "    y_train = pickle.load(f)\n",
    "with open(os.path.join(data_dirpath, 'bow_3m_reblogged_test.pkl'), 'rb') as f:\n",
    "    y_test = pickle.load(f)\n",
    "    \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><a class=\"tumblr_blog\" href=\"http://yumipuffyloki.tumblr.com/post/55496140766\">yumipuffyloki</a>:</p><blockquote> <p><strong>Every person who reblogs this will have a Pokémon egg in their s</strong><strong>ubmissions</strong> and a few days later a Pokémon will hatch from the egg.</p> <p><img alt=\"image\" src=\"https://68.media.tumblr.com/b609aa8c9dd7dd6c41bf88b926af2175/tumblr_inline_mpyursuY161qz4rgp.gif\"/></p> <p><strong>The Pokémon will be submitted based on their blog. </strong>It may be shiny or even a legendary.\\xa0(Have your submissions open and only reblog, likes do not count.)</p> </blockquote>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decide features, vectorize\n",
    "data.loc[0,'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34e2d361e7b146fd9c1bfa664c390abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2703854), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'yumipuffyloki: Every person who reblogs this will have a Pokémon egg in their submissions and a few days later a Pokémon will hatch from the egg.  The Pokémon will be submitted based on their blog. It may be shiny or even a legendary.\\xa0(Have your submissions open and only reblog, likes do not count.) '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strip HTML from post body\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.fed = []\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "    def get_data(self):\n",
    "        return ''.join(self.fed)\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "data['post_text'] = list(map(strip_tags, tqdm(data['body'].fillna(''))))\n",
    "data.loc[0, 'post_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(os.path.join(data_dirpath, 'posts_descs_3m_rebloggers.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

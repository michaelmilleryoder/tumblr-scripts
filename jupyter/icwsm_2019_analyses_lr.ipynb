{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "data_dirpath = '/usr2/mamille2/tumblr/data/sample1k'\n",
    "\n",
    "feature_tables_dir = os.path.join(data_dirpath, 'feature_tables')\n",
    "filenames = ['reblog_features.csv', 'nonreblog_features.csv', 'ranking_labels.csv']\n",
    "joined_filenames = [os.path.join(feature_tables_dir, filename) for filename in filenames]\n",
    "# csv_readers = [csv.DictReader(codecs.open(filename, 'rU', 'utf-16')) for filename in joined_filenames]\n",
    "csv_readers = [csv.DictReader(x.replace('\\0', '') for x in open(filename, 'r')) for filename in joined_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712670 712670\n"
     ]
    }
   ],
   "source": [
    "instances = []\n",
    "instance_labels = []\n",
    "for row in zip(*csv_readers):\n",
    "    reblog_features = row[0]\n",
    "    nonreblog_features = row[1]\n",
    "    label = int(row[2]['ranking_label'])\n",
    "    instance = (reblog_features, nonreblog_features) # reblog always first, nonreblog always second\n",
    "    instances.append(instance)\n",
    "    instance_labels.append(label)\n",
    "    \n",
    "print(len(instances), len(instance_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tag vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14318\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def _str2list(in_str):\n",
    "    return [el[1:-1] for el in in_str[1:-1].split(', ')]\n",
    "\n",
    "def update_tag_counts(tag_counts, counted_ids, candidate): # for hashtags\n",
    "#     candidate_tags = [tag.lower() for tag in eval(candidate['post_tags'])] # uses tokens provided in feature tables\n",
    "    candidate_tags = [tag.lower() for tag in _str2list(candidate['post_tags'])] # uses tokens provided in feature tables\n",
    "    followee_id = candidate['tumblog_id_followee']    \n",
    "    for tag in candidate_tags:\n",
    "        if not followee_id in counted_ids[tag]: # only counts the tag if user hasn't already used the tag\n",
    "            tag_counts[tag] += 1\n",
    "            counted_ids[tag].add(followee_id)\n",
    "        \n",
    "counted_ids = defaultdict(lambda: set()) # for each tag, a set of followees who used those tags\n",
    "tag_counts = defaultdict(int) # count of unique followees who used each tag\n",
    "for reblog_candidate, nonreblog_candidate in instances:\n",
    "    update_tag_counts(tag_counts, counted_ids, reblog_candidate)\n",
    "    update_tag_counts(tag_counts, counted_ids, nonreblog_candidate)\n",
    "\n",
    "tag_counts_filtered = {k:v for k,v in tag_counts.items() if v > 1} # at least 2 users used the tag\n",
    "tag_vocab = tag_counts_filtered.keys()\n",
    "print(len(tag_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identity_categories = ['age', 'ethnicity/nationality', 'fandoms', 'gender',\n",
    "                       'interests', 'location', 'personality type', 'pronouns', 'relationship status', 'roleplay',\n",
    "                       'sexual orientation', 'weight', 'zodiac']\n",
    "len(identity_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count category label instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_label_counts = defaultdict(lambda: defaultdict(int)) # {category: {value: count_of_unique_users}}\n",
    "# counted_ids = set()\n",
    "for category in identity_categories:\n",
    "    counted_ids = set() # for each category, ids already considered\n",
    "    for reblog_candidate, nonreblog_candidate in instances:\n",
    "        category_followee = category + '_terms_followee'\n",
    "        followee_id = reblog_candidate['tumblog_id_followee']\n",
    "        if not followee_id in counted_ids: # only counts labels from first instance seen of a followee, since constant\n",
    "            category_value = [x.lower() for x in eval(reblog_candidate[category_followee])]\n",
    "            for value in category_value:\n",
    "                category_label_counts[category][value] += 1\n",
    "            counted_ids.add(followee_id)\n",
    "            \n",
    "        followee_id = nonreblog_candidate['tumblog_id_followee']\n",
    "        if not followee_id in counted_ids:\n",
    "            category_value = [x.lower() for x in eval(nonreblog_candidate[category_followee])]\n",
    "            for value in category_value:\n",
    "                category_label_counts[category][value] += 1\n",
    "            counted_ids.add(followee_id)\n",
    "        \n",
    "        category_follower = category + '_terms_follower'\n",
    "        follower_id = reblog_candidate['tumblog_id_follower']\n",
    "        if not follower_id in counted_ids:\n",
    "            category_value = [x.lower() for x in eval(reblog_candidate[category_follower])]\n",
    "            for value in category_value:\n",
    "                category_label_counts[category][value] += 1\n",
    "            counted_ids.add(follower_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create category label vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age 65\n",
      "{'19', 'twelve', '56', '50', '31', '26', '58', '35', '49', '47', '11', '14', '36', '41', 'xxiv', '32', '13', '48', '10', '30', '51', '37', '40', '44', '54', 'y/o', '53', '18', '12', '45', '59', 'xxix', '22', '57', '20', '33', '34', 'eighteen', 'fourteen', 'fifty', 'twenty', '24', '27', '29', 'nineteen', 'age', 'forty', '39', '42', 'sixteen', '15', 'seventeen', '16', '43', '55', '25', '46', 'xix', '52', 'fifteen', '23', '38', '28', '17', '21'}\n",
      "-----------------\n",
      "\n",
      "ethnicity/nationality 81\n",
      "{'americans', 'indian', 'tigre', 'irish', 'southern', 'scandinavian', 'cuban', 'malaysian', 'portuguese', 'australian', 'chilena', 'finnish', 'korean', 'canadian', 'lithuanian', 'saudi', 'british', 'thai', 'mexican', 'filipino', 'french', 'romanian', 'albanian', 'white', 'ottawa', 'latino', 'italian', 'japanese', 'brazilian', 'chinese', 'russian', 'colombian', 'belgian', 'dakota', 'german', 'european', 'swedish', 'danish', 'chilean', 'mexicano', 'african', 'asian', 'czech', 'latina', 'turkish', 'norwegian', 'armenian', 'austrian', 'black', 'mexicana', 'swede', 'jamaican', 'hispanic', 'omaha', 'swiss', 'filipina', 'moroccan', 'venezuelan', 'greek', 'hungarian', 'english', 'polish', 'haitian', 'coeur', 'pakistani', 'american', 'chileno', 'malay', 'serbian', 'papel', 'dutch', 'thais', 'puerto', 'dominican', 'south african', 'indonesian', 'singaporean', 'turks', 'vietnamese', 'spanish', 'scottish'}\n",
      "-----------------\n",
      "\n",
      "fandoms 54\n",
      "{'undertale', 'riverdale', '5sos', 'reylo', 'shipper', 'voltron', 'kpop', 'swiftie', 'disney', 'comic', 'bnha', 'canon', 'phan', 'sherlock', 'k-pop', 'wwe', 'verse', 'got7', 'homestuck', 'multi-ship', 'shaladin', 'universe', 'multi-fandom', 'harry potter', 'hogwarts', 'fandom', 'stan', 'potterhead', 'yaoi', 'ereri', 'bts', 'multiship', 'marvel', 'fanatic', 'overwatch', 'army', 'twd', 'star wars', 'ships', 'mcu', 'series', 'otaku', 'hp', 'fan', 'yuri', 'hamilton', 'pokemon', 'exo', 'rey', 'tjlc', 'supercorp', 'i ship', 'multiverse', 'sims'}\n",
      "-----------------\n",
      "\n",
      "gender 33\n",
      "{'sister', 'girl', 'princess', 'dad', 'son', 'brother', 'genderfluid', 'boy', 'cis', 'lady', 'agender', 'nonbinary', 'ftm', 'androgynous', 'mommy', 'wife', 'trans', 'mtf', 'mum', 'husband', 'queen', 'guy', 'non-binary', 'male', 'man', 'lgbt', 'woman', 'daughter', 'mom', 'bigender', 'nb', 'female', 'gurl'}\n",
      "-----------------\n",
      "\n",
      "interests 71\n",
      "{'design', 'family', 'soccer', 'memes', 'draw', 'meme', 'piano', 'gifs', 'art', 'psychology', 'horror', 'comics', 'coffee', 'drawing', 'book', 'hair', 'fitness', 'desserts', 'meche', 'gaming', 'movies', 'animals', 'cat', 'reading', 'fashion', 'write', 'clarinet', 'landscapes', 'hunting', 'makeup', 'food', 'poetry', 'cosplay', 'aesthetic', 'interests', 'science', 'metal', 'writing', 'animal', 'photos', 'tea', 'dogs', 'manga', 'history', 'nutrition', 'running', 'robot', 'hockey', 'nature', 'law', 'film', 'dog', 'travel', 'tattoos', 'pies', 'arts', 'things', 'music', 'games', 'bands', 'aesthetics', 'books', 'lifestyle', 'weed', 'theatre', 'photography', 'stuff', 'tv', 'anime', 'cats', 'pizza'}\n",
      "-----------------\n",
      "\n",
      "location 146\n",
      "{'maine', 'east', 'belgium', 'pennsylvania', 'indonesia', 'sweden', 'portugal', 'alaska', 'argentina', 'arizona', 'al', 'germany', 'finland', 'kansas', 'iceland', 'denmark', 'toronto', 'socal', 'georgia', 'wa', 'massachusetts', 'new hampshire', 'az', 'istanbul', 'hawaii', 'new zealand', 'nc', 'serbia', 'nj', 'slovakia', 'tennessee', 'alabama', 'ny', 'south africa', 'united states', 'california', 'utah', 'australia', 'tampa', 'michigan', 'malaysia', 'north carolina', 'romania', 'chicago', 'venezuela', 'atl', 'va', 'costa rica', 'netherlands', 'croatia', 'pa', 'new jersey', 'maryland', 'midwest', 'switzerland', 'india', 'minnesota', 'nz', 'u.s.', 'cleveland', 'philippines', 'dc', 'u.s', 'tx', 'ga', 'north', 'greece', 'italy', 'delaware', 'albania', 'philadelphia', 'jamaica', 'chile', 'mississippi', 'hong kong', 'illinois', 'slovenia', 'athens', 'mali', 'méxico', 'virginia', 'thailand', 'norway', 'missouri', 'florida', 'philly', 'san', 'china', 'washington', 'nyc', 'usa', 'louisiana', 'israel', 'u.k', 'pnw', 'uk', 'oregon', 'oklahoma', 'czech republic', 'japan', 'ca', 'guinea', 'south carolina', 'mx', 'iowa', 'rhode island', 'london', 'ireland', 'canada', 'vietnam', 'hungary', 'jordan', 'poland', 'ct', 'cali', 'indiana', 'turkey', 'west', 'atlanta', 'i̇stanbul', 'arkansas', 'singapore', 'wisconsin', 'bulgaria', 'south', 'mexico', 'kentucky', 'colorado', 'ecuador', 'austria', 'berlin', 'france', 'madagascar', 'aus', 'chad', 'spain', 'montana', 'brazil', 'umass', 'colombia', 'new york', 'fl', 'texas', 'egypt', 'taiwan', 'ohio'}\n",
      "-----------------\n",
      "\n",
      "personality type 29\n",
      "{'enfj', 'intj', 'gryffindor', 'enfp', 'slytherin', 'hufflepuff', 'ravenclaw', 'esfp', 'extrovert', 'intp', 'lawful', 'antp', 'neutral', 'entp', 'istj', 'introvert', 'infj', '5w4', 'ambivert', 'entj', 'estp', 'isfp', 'esfj', 'istp', 'infp', 'chaotic', 'isfj', '5w6', '4w5'}\n",
      "-----------------\n",
      "\n",
      "pronouns 9\n",
      "{'him', 'her', 'xe', 'itits', 'they', 'pronouns', 'he', 'them', 'she'}\n",
      "-----------------\n",
      "\n",
      "relationship status 9\n",
      "{'wife', 'single', 'married', 'husband', 'in a relationship', 'taken', 'spouse', 'couple', 'engaged'}\n",
      "-----------------\n",
      "\n",
      "roleplay 7\n",
      "{'selective', 'rp', 'semi-selective', 'roleplay', 'm!a', 'oc', 'muse'}\n",
      "-----------------\n",
      "\n",
      "sexual orientation 18\n",
      "{'lgbt', 'wlw', 'ace', 'queer', 'bisexual', 'demisexual', 'aro/ace', 'aro-ace', 'mlm', 'homo', 'bi', 'cishet', 'pansexual', 'lesbian', 'asexual', 'straight', 'pan', 'gay'}\n",
      "-----------------\n",
      "\n",
      "weight 21\n",
      "{'gw2', 'sw', 'cw', 'gw3', 'weight', 'fat', 'ana', 'gw1', 'gw', 'bulimia', 'thin', 'lbs', 'hw', 'lw', 'anorexic', 'eating disorders', 'anorexia', 'kg', 'eating disorder', 'lb', 'pounds'}\n",
      "-----------------\n",
      "\n",
      "zodiac 7\n",
      "{'cancer', 'libra', 'virgo', 'taurus', 'leo', 'aries', 'gemini'}\n",
      "-----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_vocabs = defaultdict(lambda: set())\n",
    "for identity_category in category_label_counts:\n",
    "    category_labels_filtered_vocab = set([k for k,v in category_label_counts[identity_category].items() if v > 1]) # min 2 users using label\n",
    "    category_vocabs[identity_category] = category_labels_filtered_vocab\n",
    "    print(identity_category, len(category_vocabs[identity_category]))\n",
    "    print(category_vocabs[identity_category])\n",
    "    print('-----------------')\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    sorted_category_labels = sorted(category_labels_filtered[category].items(), key=lambda x: x[1], reverse=True)    \n",
    "    print(category)\n",
    "    print('-----------------')\n",
    "    for i in range(1, 21):\n",
    "        if i == len(sorted_category_labels):\n",
    "            break\n",
    "        print(sorted_category_labels[i][0], sorted_category_labels[i][1])\n",
    "    print('-----------------')\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_post_baseline(reblog_candidate, nonreblog_candidate, label):\n",
    "    features = defaultdict(float) # {feat: count} for each instance\n",
    "    # Comparison space features\n",
    "    def _extract_features_post_baseline_candidate(candidate, incr):\n",
    "        candidate_tags = [tag.lower() for tag in eval(candidate['post_tags'])]\n",
    "        for tag in candidate_tags:\n",
    "            if tag.lower() in tag_vocab:\n",
    "                feat_tag = ('tag=%s' % tag.lower())\n",
    "                features[feat_tag] += incr\n",
    "\n",
    "        post_type = candidate['post_type']\n",
    "        feat_tag = ('post_type=%s' % post_type)\n",
    "        features[feat_tag] += incr\n",
    "        \n",
    "        try:\n",
    "            post_note_count = float(candidate['post_note_count'])\n",
    "        except ValueError as e:\n",
    "            post_note_count = 0.0\n",
    "            \n",
    "        features['post_note_count'] += incr * post_note_count\n",
    "        \n",
    "    # if randomly-generated label is 1, second candidate is reblog, so flip: -1 is whatever candidate should consider first\n",
    "    if label == 1: \n",
    "        _extract_features_post_baseline_candidate(nonreblog_candidate, incr=-1)\n",
    "        _extract_features_post_baseline_candidate(reblog_candidate, incr=1)\n",
    "    else:\n",
    "        _extract_features_post_baseline_candidate(reblog_candidate, incr=-1)\n",
    "        _extract_features_post_baseline_candidate(nonreblog_candidate, incr=1)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Identity framing, presence of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_experiment_1(reblog_candidate, nonreblog_candidate, label):\n",
    "    # Baseline features\n",
    "#     features = defaultdict(float)\n",
    "    features = extract_features_post_baseline(reblog_candidate, nonreblog_candidate, label)\n",
    "    \n",
    "    # Follower features\n",
    "#     for identity_category in identity_categories:\n",
    "#         identity_category_follower = eval(reblog_candidate[identity_category + '_terms_follower'])\n",
    "#         follower_presence = len(identity_category_follower) > 0\n",
    "#         if follower_presence:\n",
    "#             feat_tag = ('follower_cat=%s' % identity_category)\n",
    "#             features[feat_tag] += 1\n",
    "            \n",
    "    # Follower-followee comparison space features\n",
    "    def _extract_features_experiment_1_candidate(candidate, incr):\n",
    "        \n",
    "        num_matches = 0\n",
    "        num_mismatched_follower_presents = 0\n",
    "        num_mismatched_followee_presents = 0\n",
    "        \n",
    "        for identity_category in identity_categories:\n",
    "            identity_category_follower = eval(reblog_candidate[identity_category + '_terms_follower'])\n",
    "            follower_presence = len(identity_category_follower) > 0\n",
    "            identity_category_followee = eval(candidate[identity_category + '_terms_followee'])\n",
    "            followee_presence = len(identity_category_followee) > 0\n",
    "#             if followee_presence:\n",
    "#                 feat_tag = ('followee_cat=%s' % identity_category)\n",
    "#                 features[feat_tag] += incr\n",
    "\n",
    "            # Alignment features\n",
    "#             if ((follower_presence and followee_presence) or\n",
    "#                 (not follower_presence and not followee_presence)):\n",
    "            # AND\n",
    "            if (follower_presence and followee_presence): # AND\n",
    "                feat_tag = ('aligned_cat=%s' % identity_category)\n",
    "                features[feat_tag] += incr\n",
    "                num_matches += 1\n",
    "                \n",
    "            # XOR\n",
    "            if (follower_presence and not followee_presence): # XOR\n",
    "                feat_tag = ('mismatched_follower_presents_cat=%s' % identity_category)\n",
    "                features[feat_tag] += incr\n",
    "                feat_tag = ('xor_cat=%s' % identity_category)\n",
    "                features[feat_tag] += incr\n",
    "                num_mismatched_follower_presents += 1\n",
    "            elif (not follower_presence and followee_presence): # XOR\n",
    "                feat_tag = ('mismatched_followee_presents_cat=%s' % identity_category)\n",
    "                features[feat_tag] += incr\n",
    "                feat_tag = ('xor_cat=%s' % identity_category)\n",
    "                features[feat_tag] += incr\n",
    "                num_mismatched_followee_presents += 1\n",
    "                \n",
    "        # Number of matches\n",
    "        features['num_matches'] += num_matches * incr\n",
    "        features['num_mismatched_follower_presents'] += num_mismatched_follower_presents * incr\n",
    "        features['num_mismatched_followee_presents'] += num_mismatched_followee_presents * incr\n",
    "            \n",
    "    if label == 1:\n",
    "        _extract_features_experiment_1_candidate(nonreblog_candidate, incr=-1)\n",
    "        _extract_features_experiment_1_candidate(reblog_candidate, incr=1)\n",
    "    else:\n",
    "        _extract_features_experiment_1_candidate(reblog_candidate, incr=-1)\n",
    "        _extract_features_experiment_1_candidate(nonreblog_candidate, incr=1)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_experiment_2(reblog_candidate, nonreblog_candidate, label):\n",
    "    # Baseline features\n",
    "#     features = defaultdict(float)\n",
    "#     features = extract_features_post_baseline(reblog_candidate, nonreblog_candidate, label)\n",
    "    features = extract_features_experiment_1(reblog_candidate, nonreblog_candidate, label)\n",
    "\n",
    "    \n",
    "    # Follower features\n",
    "    for identity_category in identity_categories:\n",
    "        identity_category_follower = [x.lower() for x in eval(reblog_candidate[identity_category + '_terms_follower'])]\n",
    "        for identity_label in identity_category_follower:\n",
    "            if identity_label in category_vocabs[identity_category]:\n",
    "                feat_tag = ('cat=%s,follower_lab=%s' % (identity_category, identity_label))\n",
    "                features[feat_tag] += 1\n",
    "            \n",
    "    # Comparison space features\n",
    "    def _extract_features_experiment_2_candidate(candidate, incr):\n",
    "        for identity_category in identity_categories:\n",
    "            identity_category_follower = [x.lower() for x in eval(reblog_candidate[identity_category + '_terms_follower'])]\n",
    "            identity_category_followee = [x.lower() for x in eval(reblog_candidate[identity_category + '_terms_followee'])]\n",
    "            for identity_label_followee in identity_category_followee:\n",
    "                if identity_label_followee in category_vocabs[identity_category]:\n",
    "                    feat_tag = ('cat=%s,followee_lab=%s' % (identity_category, identity_label_followee))\n",
    "                    features[feat_tag] += incr\n",
    "                    \n",
    "                    # Compatibility features: explicit marking of follower and followee labels together\n",
    "                    for identity_label_follower in identity_category_follower:\n",
    "                        if identity_label_follower in category_vocabs[identity_category]:\n",
    "                            feat_tag = ('cat=%s,follower_lab=%s,followee_lab=%s' % (identity_category,\n",
    "                                                                                    identity_label_follower,\n",
    "                                                                                    identity_label_followee))\n",
    "                            features[feat_tag] += incr\n",
    "            \n",
    "                \n",
    "    if label == 1:\n",
    "        _extract_features_experiment_2_candidate(nonreblog_candidate, incr=-1)\n",
    "        _extract_features_experiment_2_candidate(reblog_candidate, incr=1)\n",
    "    else:\n",
    "        _extract_features_experiment_2_candidate(reblog_candidate, incr=-1)\n",
    "        _extract_features_experiment_2_candidate(nonreblog_candidate, incr=1)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_extraction\n",
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:  5.5min remaining: 12.9min\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:  6.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626980229279\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for (reblog_candidate, nonreblog_candidate), label in zip(instances, instance_labels):\n",
    "    X.append(extract_features_post_baseline(reblog_candidate, nonreblog_candidate, label))\n",
    "    y.append(label)\n",
    "    \n",
    "post_features_vectorizer = feature_extraction.DictVectorizer()\n",
    "post_features_scaler = preprocessing.StandardScaler(with_mean=False) # normalization standard scaler\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=12345)\n",
    "X_train = post_features_vectorizer.fit_transform(X_train)\n",
    "X_train = post_features_scaler.fit_transform(X_train)\n",
    "X_test = post_features_vectorizer.transform(X_test)\n",
    "X_test = post_features_scaler.transform(X_test)\n",
    "\n",
    "baseline_model = linear_model.LogisticRegressionCV(cv=10, n_jobs=10, max_iter=1000, verbose=2).fit(X_train, y_train) # default 5 folds\n",
    "print(baseline_model.score(X_test, y_test))\n",
    "baseline_pred = baseline_model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "np.savetxt(os.path.join(data_dirpath, 'results', 'baseline.txt'), baseline_pred)\n",
    "\n",
    "# Save classifier (with weights)\n",
    "with open(os.path.join(data_dirpath, 'models', 'lr_baseline.pkl'), 'wb') as f:\n",
    "    pickle.dump(baseline_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1 - Identity framing, presence of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done   3 out of  10 | elapsed:  3.6min remaining:  8.5min\n",
      "[Parallel(n_jobs=10)]: Done  10 out of  10 | elapsed:  4.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641608318015\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for (reblog_candidate, nonreblog_candidate), label in zip(instances, instance_labels):\n",
    "    X.append(extract_features_experiment_1(reblog_candidate, nonreblog_candidate, label))\n",
    "    y.append(label)\n",
    "    \n",
    "features_vectorizer_experiment_1 = feature_extraction.DictVectorizer()\n",
    "features_scaler_experiment_1 = preprocessing.StandardScaler(with_mean=False)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=12345)\n",
    "X_train = features_vectorizer_experiment_1.fit_transform(X_train)\n",
    "X_train = features_scaler_experiment_1.fit_transform(X_train)\n",
    "X_test = features_vectorizer_experiment_1.transform(X_test)\n",
    "X_test = features_scaler_experiment_1.transform(X_test)\n",
    "\n",
    "experiment_1_model = linear_model.LogisticRegressionCV(cv=10, n_jobs=10, max_iter=1000, verbose=2).fit(X_train, y_train)\n",
    "print(experiment_1_model.score(X_test, y_test))\n",
    "experiment_1_pred = experiment_1_model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "np.savetxt(os.path.join(data_dirpath, 'results', 'baseline_exp1.txt'), experiment_1_pred)\n",
    "\n",
    "# Save classifier (with weights)\n",
    "with open(os.path.join(data_dirpath, 'models', 'lr_baseline_exp1.pkl'), 'wb') as f:\n",
    "    pickle.dump(experiment_1_model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2 - Compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Done   7 out of  10 | elapsed: 10.8min remaining:  4.6min\n",
      "[Parallel(n_jobs=5)]: Done  10 out of  10 | elapsed: 11.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641678476714\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "for (reblog_candidate, nonreblog_candidate), label in zip(instances, instance_labels):\n",
    "    X.append(extract_features_experiment_2(reblog_candidate, nonreblog_candidate, label))\n",
    "    y.append(label)\n",
    "    \n",
    "features_vectorizer_experiment_2 = feature_extraction.DictVectorizer()\n",
    "features_scaler_experiment_2 = preprocessing.StandardScaler(with_mean=False)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=12345)\n",
    "X_train = features_vectorizer_experiment_2.fit_transform(X_train)\n",
    "X_train = features_scaler_experiment_2.fit_transform(X_train)\n",
    "X_test = features_vectorizer_experiment_2.transform(X_test)\n",
    "X_test = features_scaler_experiment_2.transform(X_test)\n",
    "\n",
    "experiment_2_model = linear_model.LogisticRegressionCV(cv=10, max_iter=1000, n_jobs=5, verbose=2).fit(X_train, y_train)\n",
    "print(experiment_2_model.score(X_test, y_test))\n",
    "experiment_2_pred = experiment_2_model.predict(X_test)\n",
    "\n",
    "# Save predictions\n",
    "np.savetxt(os.path.join(data_dirpath, 'results', 'baseline_exp1_exp2.txt'), experiment_2_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McNemar's Test (Significance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75136, 14230], [16315, 36853]]\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "b = 0 # Baseline correct, experiment incorrect\n",
    "c = 0 # Baseline incorrect, experiment correct\n",
    "d = 0\n",
    "for b_pred, ex_pred, true in zip(baseline_pred, experiment_1_pred, y_test):\n",
    "    if b_pred == true and ex_pred == true:\n",
    "        a += 1\n",
    "    elif b_pred == true and ex_pred != true:\n",
    "        b += 1\n",
    "    elif b_pred != true and ex_pred == true:\n",
    "        c += 1\n",
    "    else:\n",
    "        d += 1\n",
    "        \n",
    "table = [[a, b],\n",
    "         [c, d]]\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic=142.322, p-value=0.000000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "# Example of calculating the mcnemar test\n",
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "# calculate mcnemar test\n",
    "result = mcnemar(table, exact=False, correction=False)\n",
    "# summarize the finding\n",
    "print('statistic=%.3f, p-value=%.6f' % (result.statistic, result.pvalue))\n",
    "# interpret the p-value\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "\tprint('Same proportions of errors (fail to reject H0)')\n",
    "else:\n",
    "\tprint('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14294"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats_index2name = {v: k for k, v in features_vectorizer_experiment_1.vocabulary_.items()}\n",
    "len(feats_index2name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14294"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_weights = experiment_1_model.coef_[0]\n",
    "len(feature_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_informative_features(feature_vectorizer, model, n=1000):\n",
    "    feats_index2name = {v: k for k, v in features_vectorizer_experiment_1.vocabulary_.items()}\n",
    "    feature_weights = experiment_1_model.coef_[0]\n",
    "    \n",
    "    top_indices = np.argsort(feature_weights)[-1*n:]\n",
    "    top_weights = np.sort(feature_weights)[-1*n:]\n",
    "    bottom_indices = np.argsort(feature_weights)[:n]\n",
    "    bottom_weights = np.sort(feature_weights)[:n]\n",
    "    \n",
    "    for i, (j, w) in enumerate(zip(reversed(top_indices), reversed(top_weights))):\n",
    "        feature_name = feats_index2name[j]\n",
    "        if not feature_name.startswith('tag'):\n",
    "            print(f\"{i}\\t{feature_name}\\t{w: .3f}\")\n",
    "            \n",
    "    for i, (j, w) in enumerate(zip(bottom_indices, bottom_weights)):\n",
    "        feature_name = feats_index2name[j]\n",
    "        if not feature_name.startswith('tag'):\n",
    "            print(f\"{i}\\t{feature_name}\\t{w: .3f}\")\n",
    "#         print(f\"{i}\\t{feature_name}\\t{w: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_features(feature_vectorizer, model, n=100):\n",
    "    feats_index2name = {v: k for k, v in features_vectorizer_experiment_1.vocabulary_.items()}\n",
    "    feature_weights = experiment_1_model.coef_[0]\n",
    "    \n",
    "    top_indices = np.argsort(feature_weights)[-1*n:]\n",
    "    top_weights = np.sort(feature_weights)[-1*n:]\n",
    "    \n",
    "    for i, (j, w) in enumerate(zip(reversed(top_indices), reversed(top_weights))):\n",
    "        feature_name = feats_index2name[j]\n",
    "        if not feature_name.startswith('tag'):\n",
    "            print(f\"{i}\\t{feature_name}\\t{w: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "def print_bottom_features(feature_vectorizer, model, n=100):\n",
    "    feats_index2name = {v: k for k, v in features_vectorizer_experiment_1.vocabulary_.items()}\n",
    "    feature_weights = experiment_1_model.coef_[0]\n",
    "    \n",
    "    bottom_indices = np.argsort(feature_weights)[:n]\n",
    "    bottom_weights = np.sort(feature_weights)[:n]\n",
    "#     set_trace()\n",
    "    \n",
    "    for i, (j, w) in enumerate(zip(bottom_indices, bottom_weights)):\n",
    "        feature_name = feats_index2name[j]\n",
    "        if not feature_name.startswith('tag'):\n",
    "            print(f\"{i}\\t{feature_name}\\t{w: .3f}\")\n",
    "#         print(f\"{i}\\t{feature_name}\\t{w: .3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\tpost_type=video\t 0.143\n",
      "11\tpost_type=photo\t 0.125\n",
      "166\tpost_type=text\t 0.057\n",
      "182\tpost_type=quote\t 0.054\n",
      "213\tmismatched_followee_presents_cat=location\t 0.052\n",
      "335\tpost_type=chat\t 0.043\n",
      "381\taligned_cat=pronouns\t 0.041\n",
      "415\txor_cat=location\t 0.039\n",
      "629\tpost_note_count\t 0.031\n",
      "792\tmismatched_followee_presents_cat=weight\t 0.027\n",
      "824\txor_cat=weight\t 0.026\n"
     ]
    }
   ],
   "source": [
    "print_top_features(features_vectorizer_experiment_1, experiment_1_model, n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\tpost_type=answer\t-0.884\n",
      "144\tmismatched_followee_presents_cat=interests\t-0.073\n",
      "192\txor_cat=interests\t-0.065\n",
      "226\tmismatched_followee_presents_cat=age\t-0.062\n",
      "245\tpost_type=link\t-0.060\n",
      "347\txor_cat=age\t-0.052\n",
      "664\tmismatched_follower_presents_cat=pronouns\t-0.041\n"
     ]
    }
   ],
   "source": [
    "print_bottom_features(features_vectorizer_experiment_1, experiment_1_model, n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix (N/A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positives: 43065\n",
      "True negatives: 48379\n",
      "False positives: 22776\n",
      "False negatives: 28314\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[48379, 22776], [28314, 43065]]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, experiment_1_pred).ravel()\n",
    "print(f\"True positives: {tp}\")\n",
    "print(f\"True negatives: {tn}\")\n",
    "print(f\"False positives: {fp}\")\n",
    "print(f\"False negatives: {fn}\")\n",
    "[[tn, fp],\n",
    "[fn, tp]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specific errors\n",
    "Look for specific times when have a feature but is still giving an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_name = 'aligned_cat=pronouns'\n",
    "feature_index = features_vectorizer_experiment_1.vocab_[feature_name]\n",
    "positive_examples = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

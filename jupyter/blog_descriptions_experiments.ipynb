{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re\n",
    "import ast\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.decomposition import TruncatedSVD, PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.manifold import TSNE\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Embedding, Flatten\n",
    "\n",
    "import os,sys,inspect\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "# from .. import gaussian_mixture_cotrain\n",
    "from gaussian_mixture_cotrain import GaussianMixtureCotrain\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from IPython.core.debugger import set_trace\n",
    "from IPython.display import display\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import fasttext as ft\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Restrict GPUs\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN to predict category mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tumblog_id', 'activity_time_epoch', 'tumblr_blog_name',\n",
      "       'tumblr_blog_title', 'tumblr_blog_description', 'tumblr_blog_url',\n",
      "       'tumblr_blog_theme', 'is_group_blog', 'is_primary', 'is_private',\n",
      "       'created_time_epoch', 'updated_time_epoch', 'timezone', 'language',\n",
      "       'blog_classifier', 'generated_date', 'parsed_blog_description',\n",
      "       'segments', 'restr_segments_25', 'segments_25_nopunct', 'age', 'gender',\n",
      "       'sexual orientation', 'pronouns', 'personality type',\n",
      "       'ethnicity/nationality', 'relationship status', 'sexuality/gender'],\n",
      "      dtype='object')\n",
      "6902\n"
     ]
    }
   ],
   "source": [
    "# Load descriptions\n",
    "descs = pd.read_pickle('/usr0/home/mamille2/tumblr/data/list_descriptions_100posts.pkl')\n",
    "print(descs.columns)\n",
    "print(len(descs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['post_id', 'activity_time_epoch', 'tumblog_id', 'post_title',\n",
      "       'post_short_url', 'post_type', 'post_caption', 'post_format',\n",
      "       'post_note_count', 'created_time_epoch', 'updated_time_epoch',\n",
      "       'is_submission', 'source_title', 'source_url', 'post_classifier',\n",
      "       'blog_classifier', 'accepts_answers', 'reblogged_from_post_id',\n",
      "       'reblogged_from_metadata', 'root_post_id', 'body', 'mentions',\n",
      "       'post_tags', 'body_toks', 'body_str'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "690200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load text posts\n",
    "posts = pd.read_pickle('/usr0/home/mamille2/tumblr/data/textposts_recent100_100posts.pkl')\n",
    "print(posts.columns)\n",
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tids = sorted(descs['tumblog_id'].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6902"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text posts to word indices (Keras way)\n",
    "texts = [' '.join(posts[posts['tumblog_id']==tid]['body_str']) for tid in tids] # concatenated posts\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 528107 unique words\n"
     ]
    }
   ],
   "source": [
    "MAX_VOCAB_SIZE = 100000\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE,\n",
    "                     filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n‚Äú‚Äù')\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print(f'Found {len(word_index)} unique words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6902"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 20000\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = list(word_index.keys())[:MAX_VOCAB_SIZE] # lower indices are words kept\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare description categories (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6902, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cats = descs.columns.tolist()[-8:]\n",
    "labels = list(zip(*[descs[cat] for cat in cats]))\n",
    "labels = np.array(labels, dtype=int)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6212, 20000)\n",
      "(6212, 8)\n",
      "(690, 20000)\n",
      "(690, 8)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle, split into train/test\n",
    "indices = np.arange(data.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]\n",
    "\n",
    "TEST_SPLIT = 0.1\n",
    "num_test_samples = int(TEST_SPLIT * data.shape[0])\n",
    "x_train = data[:-num_test_samples]\n",
    "print(x_train.shape)\n",
    "y_train = labels[:-num_test_samples]\n",
    "print(y_train.shape)\n",
    "x_test = data[-num_test_samples:]\n",
    "print(x_test.shape)\n",
    "y_test = labels[-num_test_samples:]\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build CNN model in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocab embeddings\n",
    "vocab_embed = np.load('/usr0/home/mamille2/tumblr/data/recent100_100posts_embeds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare model\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "embedding_layer = Embedding(len(vocab),\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights = [vocab_embed],\n",
    "                            input_length = MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False\n",
    "                           )\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(embedding_layer)\n",
    "model.add(Conv1D(1024, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "model.add(Conv1D(128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(8, activation='sigmoid')) # final classification layer\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6212 samples, validate on 690 samples\n",
      "Epoch 1/3\n",
      "6212/6212 [==============================] - 162s 26ms/step - loss: 0.0219 - val_loss: 1.2936\n",
      "Epoch 2/3\n",
      "6212/6212 [==============================] - 165s 27ms/step - loss: 0.0188 - val_loss: 1.3979\n",
      "Epoch 3/3\n",
      "6212/6212 [==============================] - 165s 27ms/step - loss: 0.0154 - val_loss: 1.3624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe4e7e5d978>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "         batch_size=16, epochs=3, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('/usr0/home/mamille2/tumblr/data/100posts_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load word embeddings (from Tumblr halfday)\n",
    "wd_embed = ft.load_model('/usr0/home/mamille2/tumblr/data/halfday_ft.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 300)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build lookup table\n",
    "vocab_embed = np.empty((len(vocab),300))\n",
    "for i, wd in enumerate(vocab):\n",
    "    vocab_embed[i,:] = wd_embed[wd]\n",
    "    \n",
    "vocab_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vocab embeddings\n",
    "np.save('/usr0/home/mamille2/tumblr/data/recent100_100posts_embeds.npy', vocab_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.894233555491162"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cutoff = 20000\n",
    "len([l for l in lens if l <= cutoff])/len(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10382.1618371\n",
      "7459.0\n",
      "416462\n"
     ]
    }
   ],
   "source": [
    "# Examine sequence lengths\n",
    "lens = [len(s) for s in sequences]\n",
    "\n",
    "print(np.mean(lens))\n",
    "print(np.median(lens))\n",
    "print(max(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6902"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text posts to word indices (Graham's way)\n",
    "post_inds = []\n",
    "\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "UNK = w2i[\"<unk>\"] # 0 index\n",
    "\n",
    "for tid in tids:\n",
    "    toks = [t for p in posts[posts['tumblog_id']==tid]['body_toks'].tolist() for t in p]\n",
    "    inds = [w2i[t] for t in toks]\n",
    "    post_inds.append(inds) \n",
    "    \n",
    "len(post_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616144"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vocab size\n",
    "len(w2i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample instances marked for certain identity categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tumblog_id', 'restr_segments_25', 'non-English', 'age', 'name',\n",
      "       'personal description/commentary', 'location', 'interests',\n",
      "       'adult content', 'sexual orientation', 'pronouns', 'gender', 'fandoms',\n",
      "       'link to external content', 'occupation', 'astrological sign',\n",
      "       'personality type', 'ethnicity/nationality', 'relationship status',\n",
      "       'mental health', 'other/notes'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load labeled data\n",
    "split = {}\n",
    "s = 'train1000'\n",
    "split[s] = pd.read_csv(f'/usr0/home/mamille2/tumblr/data/list_descriptions_{s}.csv', index_col=0)\n",
    "print(split[s].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non-English\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>non-English</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5673831</th>\n",
       "      <td>['sin tus caricias', 'nena', '¬øque va a ser de mi?']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5589904</th>\n",
       "      <td>['blog bandar ceme online', 'poker88', 'domino qiu qiu', 'capsa']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6036680</th>\n",
       "      <td>['czas nie leczy ran']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4963722</th>\n",
       "      <td>[\"et c'est du lolz en barre\"]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2961991</th>\n",
       "      <td>['bisserl was von allem']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         restr_segments_25  \\\n",
       "5673831  ['sin tus caricias', 'nena', '¬øque va a ser de mi?']                \n",
       "5589904  ['blog bandar ceme online', 'poker88', 'domino qiu qiu', 'capsa']   \n",
       "6036680  ['czas nie leczy ran']                                              \n",
       "4963722  [\"et c'est du lolz en barre\"]                                       \n",
       "2961991  ['bisserl was von allem']                                           \n",
       "\n",
       "         non-English  \n",
       "5673831  1.0          \n",
       "5589904  1.0          \n",
       "6036680  1.0          \n",
       "4963722  1.0          \n",
       "2961991  1.0          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "age\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4675110</th>\n",
       "      <td>['stark depressiv', '19 jahre']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5679736</th>\n",
       "      <td>['19', 'üëÖnaturally unbothered ‚ú®', 'love your melanin üçØ']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4803395</th>\n",
       "      <td>['18', 'cali', 'bi']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3689594</th>\n",
       "      <td>['ani', '16']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704999</th>\n",
       "      <td>['19', 'infp', 'cap', 'sensitive black person']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                restr_segments_25  age\n",
       "4675110  ['stark depressiv', '19 jahre']                           1.0\n",
       "5679736  ['19', 'üëÖnaturally unbothered ‚ú®', 'love your melanin üçØ']  1.0\n",
       "4803395  ['18', 'cali', 'bi']                                      1.0\n",
       "3689594  ['ani', '16']                                             1.0\n",
       "2704999  ['19', 'infp', 'cap', 'sensitive black person']           1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "name\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4621537</th>\n",
       "      <td>['claudia', 'xxi']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050064</th>\n",
       "      <td>['call me grace ^^', 'libra', 'pansexual to the core', 'she/her', 'in university']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358217</th>\n",
       "      <td>['dustin', '20']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2098049</th>\n",
       "      <td>['frankie wolff', '21', 'hella gay']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741580</th>\n",
       "      <td>['catalina', '15', 'chile', 'sagitario', '24-05-17']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                          restr_segments_25  \\\n",
       "4621537  ['claudia', 'xxi']                                                                   \n",
       "1050064  ['call me grace ^^', 'libra', 'pansexual to the core', 'she/her', 'in university']   \n",
       "2358217  ['dustin', '20']                                                                     \n",
       "2098049  ['frankie wolff', '21', 'hella gay']                                                 \n",
       "4741580  ['catalina', '15', 'chile', 'sagitario', '24-05-17']                                 \n",
       "\n",
       "         name  \n",
       "4621537  1.0   \n",
       "1050064  1.0   \n",
       "2358217  1.0   \n",
       "2098049  1.0   \n",
       "4741580  1.0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "location\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3911020</th>\n",
       "      <td>['ash', '21', 'uk  ‚ô• 18+ side blog ‚ô•']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3639661</th>\n",
       "      <td>['24 years old', 'lost angeles', 'fat princess']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243880</th>\n",
       "      <td>['hi i\\'m shiba nagame\", \\'living in japan', 'writing fanfics']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2363701</th>\n",
       "      <td>['birmingham']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1656661</th>\n",
       "      <td>['aberto a sugest√µes', 'sou de portugal', 'aceito tudo menos homens']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             restr_segments_25  \\\n",
       "3911020  ['ash', '21', 'uk  ‚ô• 18+ side blog ‚ô•']                                  \n",
       "3639661  ['24 years old', 'lost angeles', 'fat princess']                        \n",
       "1243880  ['hi i\\'m shiba nagame\", \\'living in japan', 'writing fanfics']         \n",
       "2363701  ['birmingham']                                                          \n",
       "1656661  ['aberto a sugest√µes', 'sou de portugal', 'aceito tudo menos homens']   \n",
       "\n",
       "         location  \n",
       "3911020  1.0       \n",
       "3639661  1.0       \n",
       "1243880  1.0       \n",
       "2363701  1.0       \n",
       "1656661  1.0       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "interests\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>interests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110729</th>\n",
       "      <td>['fashion', 'luxury', 'homme', 'paris', 'morocco germany,bochum']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745368</th>\n",
       "      <td>['22', 'jesus follower', 'nature', 'coffee', 'traveler']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1243880</th>\n",
       "      <td>['hi i\\'m shiba nagame\", \\'living in japan', 'writing fanfics']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5088035</th>\n",
       "      <td>['writer', 'high school sophomore', 'homeschooled']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914497</th>\n",
       "      <td>['merel', 'she/her', 'dutch', 'likes tacos and bad music']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         restr_segments_25  \\\n",
       "110729   ['fashion', 'luxury', 'homme', 'paris', 'morocco germany,bochum']   \n",
       "745368   ['22', 'jesus follower', 'nature', 'coffee', 'traveler']            \n",
       "1243880  ['hi i\\'m shiba nagame\", \\'living in japan', 'writing fanfics']     \n",
       "5088035  ['writer', 'high school sophomore', 'homeschooled']                 \n",
       "4914497  ['merel', 'she/her', 'dutch', 'likes tacos and bad music']          \n",
       "\n",
       "         interests  \n",
       "110729   1.0        \n",
       "745368   1.0        \n",
       "1243880  1.0        \n",
       "5088035  1.0        \n",
       "4914497  1.0        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "adult content\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>adult content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2337898</th>\n",
       "      <td>['female', '25', 'in a good working rl', 'german', 'filthy 18+ only!!!']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4712484</th>\n",
       "      <td>['consent is a must', 'enjoy']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859624</th>\n",
       "      <td>['i love', ':-) only 18+!!!']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6276166</th>\n",
       "      <td>['nsfw 18+ blog he/him', 'gay', '19 snapchat: donk811']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5405668</th>\n",
       "      <td>['jack', '18', 'uk', 'nsfw']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                restr_segments_25  \\\n",
       "2337898  ['female', '25', 'in a good working rl', 'german', 'filthy 18+ only!!!']   \n",
       "4712484  ['consent is a must', 'enjoy']                                             \n",
       "859624   ['i love', ':-) only 18+!!!']                                              \n",
       "6276166  ['nsfw 18+ blog he/him', 'gay', '19 snapchat: donk811']                    \n",
       "5405668  ['jack', '18', 'uk', 'nsfw']                                               \n",
       "\n",
       "         adult content  \n",
       "2337898  1.0            \n",
       "4712484  1.0            \n",
       "859624   1.0            \n",
       "6276166  1.0            \n",
       "5405668  1.0            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "sexual orientation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>sexual orientation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2153632</th>\n",
       "      <td>['24, genderfluid, pan', 'bisexual, she', 'her, and they']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5465464</th>\n",
       "      <td>['28', 'straight', '18+']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685360</th>\n",
       "      <td>['she/her', '22', 'pagan', 'pansexual', 'in shipping hell']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324390</th>\n",
       "      <td>['meow\\', \"i\\'m also very ace,so']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3047905</th>\n",
       "      <td>['alex or aldamert', 'he/him', 'pan as fuck']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   restr_segments_25  \\\n",
       "2153632  ['24, genderfluid, pan', 'bisexual, she', 'her, and they']    \n",
       "5465464  ['28', 'straight', '18+']                                     \n",
       "685360   ['she/her', '22', 'pagan', 'pansexual', 'in shipping hell']   \n",
       "2324390  ['meow\\', \"i\\'m also very ace,so']                            \n",
       "3047905  ['alex or aldamert', 'he/him', 'pan as fuck']                 \n",
       "\n",
       "         sexual orientation  \n",
       "2153632  1.0                 \n",
       "5465464  1.0                 \n",
       "685360   1.0                 \n",
       "2324390  1.0                 \n",
       "3047905  1.0                 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gender\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4465201</th>\n",
       "      <td>['24', 'a place for myself', 'a curious girl exploring', '18+', 'submit if you want']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5449959</th>\n",
       "      <td>['20 yo girl', 'italian', 'sad stuff lover']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6137916</th>\n",
       "      <td>['20', 'lg(b)t', 'east coast ü§î']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359256</th>\n",
       "      <td>['s~twenty~female', 'star wars']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2142277</th>\n",
       "      <td>['closeted bisexual', 'cis female', 'presbyterian']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                             restr_segments_25  \\\n",
       "4465201  ['24', 'a place for myself', 'a curious girl exploring', '18+', 'submit if you want']   \n",
       "5449959  ['20 yo girl', 'italian', 'sad stuff lover']                                            \n",
       "6137916  ['20', 'lg(b)t', 'east coast ü§î']                                                        \n",
       "359256   ['s~twenty~female', 'star wars']                                                        \n",
       "2142277  ['closeted bisexual', 'cis female', 'presbyterian']                                     \n",
       "\n",
       "         gender  \n",
       "4465201  1.0     \n",
       "5449959  1.0     \n",
       "6137916  1.0     \n",
       "359256   1.0     \n",
       "2142277  1.0     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "pronouns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>pronouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1965062</th>\n",
       "      <td>['charlotte', 'she/her', 'i like sims and cats']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5107489</th>\n",
       "      <td>['archer', 'va -&gt; nyc', '22', 'she/her']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4914497</th>\n",
       "      <td>['merel', 'she/her', 'dutch', 'likes tacos and bad music']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3774318</th>\n",
       "      <td>['slytherin', 'libra', 'intp', 'she/her']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4944383</th>\n",
       "      <td>['ezra', 'he']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  restr_segments_25  pronouns\n",
       "1965062  ['charlotte', 'she/her', 'i like sims and cats']            1.0     \n",
       "5107489  ['archer', 'va -> nyc', '22', 'she/her']                    1.0     \n",
       "4914497  ['merel', 'she/her', 'dutch', 'likes tacos and bad music']  1.0     \n",
       "3774318  ['slytherin', 'libra', 'intp', 'she/her']                   1.0     \n",
       "4944383  ['ezra', 'he']                                              1.0     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "fandoms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>fandoms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5771853</th>\n",
       "      <td>['not many understand this', '-slh']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5703809</th>\n",
       "      <td>['hey! katie', 'she/hers', 'def not straight', 'infj', 'too many fandoms to count']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944531</th>\n",
       "      <td>['actually quite mellow', 'gnu terry pratchett']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5696938</th>\n",
       "      <td>['yaoi', 'manhwa', 'persona 5', 'danganronpa', 'memes', 'stupidity', 'occasional nsfw', 'spoilers, probably']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5012730</th>\n",
       "      <td>['multi-verse friendly']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                     restr_segments_25  \\\n",
       "5771853  ['not many understand this', '-slh']                                                                            \n",
       "5703809  ['hey! katie', 'she/hers', 'def not straight', 'infj', 'too many fandoms to count']                             \n",
       "944531   ['actually quite mellow', 'gnu terry pratchett']                                                                \n",
       "5696938  ['yaoi', 'manhwa', 'persona 5', 'danganronpa', 'memes', 'stupidity', 'occasional nsfw', 'spoilers, probably']   \n",
       "5012730  ['multi-verse friendly']                                                                                        \n",
       "\n",
       "         fandoms  \n",
       "5771853  1.0      \n",
       "5703809  1.0      \n",
       "944531   1.0      \n",
       "5696938  1.0      \n",
       "5012730  1.0      "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "link to external content\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>link to external content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3472827</th>\n",
       "      <td>['23', 'auckland', 'sc - thikcock99']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722189</th>\n",
       "      <td>['mother earth goddess', 'philosopher    portfolio', 'original account', 'soundcloud', 'instagram']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388946</th>\n",
       "      <td>['www', 'neifatti', 'it']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259815</th>\n",
       "      <td>['eden', 'wa', 'sc: eden5601', 'ig: edenhackett_', 'various mcelroy podcast', 'r&amp;m', 'anti-onision', 'pro-dogs', 'mcu']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3653510</th>\n",
       "      <td>['‚ôå leonina', 'instagram : myllabitte', 'twitter : @myllab19', 'snapchat : myllabitte']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                               restr_segments_25  \\\n",
       "3472827  ['23', 'auckland', 'sc - thikcock99']                                                                                     \n",
       "722189   ['mother earth goddess', 'philosopher    portfolio', 'original account', 'soundcloud', 'instagram']                       \n",
       "5388946  ['www', 'neifatti', 'it']                                                                                                 \n",
       "5259815  ['eden', 'wa', 'sc: eden5601', 'ig: edenhackett_', 'various mcelroy podcast', 'r&m', 'anti-onision', 'pro-dogs', 'mcu']   \n",
       "3653510  ['‚ôå leonina', 'instagram : myllabitte', 'twitter : @myllab19', 'snapchat : myllabitte']                                   \n",
       "\n",
       "         link to external content  \n",
       "3472827  1.0                       \n",
       "722189   1.0                       \n",
       "5388946  1.0                       \n",
       "5259815  1.0                       \n",
       "3653510  1.0                       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "occupation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>occupation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>773799</th>\n",
       "      <td>['i\\'m a writer\", \\'a very unsuccessful one']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4510358</th>\n",
       "      <td>['liz menco', '30', 'museum archivist', 'spiritualist']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165856</th>\n",
       "      <td>['dob : 2', '1999  university student']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117754</th>\n",
       "      <td>['photographer', 'videographer', 'coffee lover', 'outdoors enthusiast', 'adventure seeker', 'wild at heart']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1852102</th>\n",
       "      <td>['sam', 'female', 'writer']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                    restr_segments_25  \\\n",
       "773799   ['i\\'m a writer\", \\'a very unsuccessful one']                                                                  \n",
       "4510358  ['liz menco', '30', 'museum archivist', 'spiritualist']                                                        \n",
       "4165856  ['dob : 2', '1999  university student']                                                                        \n",
       "117754   ['photographer', 'videographer', 'coffee lover', 'outdoors enthusiast', 'adventure seeker', 'wild at heart']   \n",
       "1852102  ['sam', 'female', 'writer']                                                                                    \n",
       "\n",
       "         occupation  \n",
       "773799   1.0         \n",
       "4510358  1.0         \n",
       "4165856  1.0         \n",
       "117754   1.0         \n",
       "1852102  1.0         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "personality type\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>personality type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1320569</th>\n",
       "      <td>['ü•Ä they', 'them or he', 'him , infp , pisces, bi ü•Ä']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796799</th>\n",
       "      <td>['17', 'entp', 'chaotic neutral']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1949761</th>\n",
       "      <td>['c a i t l y n', 'i n f j', 'a r t i s t', 'r e a d e r', 'e t c']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919024</th>\n",
       "      <td>['zana', '| infj-t', '| xvii', '| aquarius', '| ravenclaw']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112798</th>\n",
       "      <td>['infp - eighteen - england', 'gap year 07', '2017-08']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                           restr_segments_25  \\\n",
       "1320569  ['ü•Ä they', 'them or he', 'him , infp , pisces, bi ü•Ä']                 \n",
       "4796799  ['17', 'entp', 'chaotic neutral']                                     \n",
       "1949761  ['c a i t l y n', 'i n f j', 'a r t i s t', 'r e a d e r', 'e t c']   \n",
       "1919024  ['zana', '| infj-t', '| xvii', '| aquarius', '| ravenclaw']           \n",
       "2112798  ['infp - eighteen - england', 'gap year 07', '2017-08']               \n",
       "\n",
       "         personality type  \n",
       "1320569  1.0               \n",
       "4796799  1.0               \n",
       "1949761  1.0               \n",
       "1919024  1.0               \n",
       "2112798  1.0               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "astrological sign\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>astrological sign</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4329683</th>\n",
       "      <td>['crystal', '19', 'us', 'aries', 'tags']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976880</th>\n",
       "      <td>['callum', '18', 'leo']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596669</th>\n",
       "      <td>['23', 'hufflepuff', 'pukwudgie', 'aquarius']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3529381</th>\n",
       "      <td>['scorpio moon', 'cancer moon']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822579</th>\n",
       "      <td>['georgie', '19', 'aro-ace', 'she/her', 'cancer/tiger']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               restr_segments_25  \\\n",
       "4329683  ['crystal', '19', 'us', 'aries', 'tags']                  \n",
       "976880   ['callum', '18', 'leo']                                   \n",
       "3596669  ['23', 'hufflepuff', 'pukwudgie', 'aquarius']             \n",
       "3529381  ['scorpio moon', 'cancer moon']                           \n",
       "2822579  ['georgie', '19', 'aro-ace', 'she/her', 'cancer/tiger']   \n",
       "\n",
       "         astrological sign  \n",
       "4329683  1.0                \n",
       "976880   1.0                \n",
       "3596669  1.0                \n",
       "3529381  1.0                \n",
       "2822579  1.0                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ethnicity/nationality\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>ethnicity/nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5482224</th>\n",
       "      <td>['italian girl of age 19', 'deeply feminist']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31575</th>\n",
       "      <td>['twenty three', 'social justice advocate', 'lover of jesus &amp; people']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5449959</th>\n",
       "      <td>['20 yo girl', 'italian', 'sad stuff lover']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4833409</th>\n",
       "      <td>['dom', 'russian', 'he/him', 'can draw']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981270</th>\n",
       "      <td>['william', '18', 'french &amp; politics', 'üè≥Ô∏è\\\\u200düåà']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              restr_segments_25  \\\n",
       "5482224  ['italian girl of age 19', 'deeply feminist']                            \n",
       "31575    ['twenty three', 'social justice advocate', 'lover of jesus & people']   \n",
       "5449959  ['20 yo girl', 'italian', 'sad stuff lover']                             \n",
       "4833409  ['dom', 'russian', 'he/him', 'can draw']                                 \n",
       "4981270  ['william', '18', 'french & politics', 'üè≥Ô∏è\\\\u200düåà']                     \n",
       "\n",
       "         ethnicity/nationality  \n",
       "5482224  1.0                    \n",
       "31575    1.0                    \n",
       "5449959  1.0                    \n",
       "4833409  1.0                    \n",
       "4981270  1.0                    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "relationship status\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>relationship status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5908287</th>\n",
       "      <td>['eli (eee-lie)', 'he', 'him', 'mlm', 'i love my bf', 'my bf', 'posts about him']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2115340</th>\n",
       "      <td>['happily married couple']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222904</th>\n",
       "      <td>['engaged', 'bored', 'tired']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914412</th>\n",
       "      <td>[\"i'm a single  male\"]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5353918</th>\n",
       "      <td>['nsfw', 'taken']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         restr_segments_25  \\\n",
       "5908287  ['eli (eee-lie)', 'he', 'him', 'mlm', 'i love my bf', 'my bf', 'posts about him']   \n",
       "2115340  ['happily married couple']                                                          \n",
       "6222904  ['engaged', 'bored', 'tired']                                                       \n",
       "5914412  [\"i'm a single  male\"]                                                              \n",
       "5353918  ['nsfw', 'taken']                                                                   \n",
       "\n",
       "         relationship status  \n",
       "5908287  1.0                  \n",
       "2115340  1.0                  \n",
       "6222904  1.0                  \n",
       "5914412  1.0                  \n",
       "5353918  1.0                  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mental health\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>mental health</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3784240</th>\n",
       "      <td>['19', 'sad', 'lonely\\\\\\\\\\\\\\\\miserable\\\\\\\\\\\\\\\\']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5541049</th>\n",
       "      <td>['depressed teen', '16']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5592086</th>\n",
       "      <td>['anxieties']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5897239</th>\n",
       "      <td>['fitness', 'foodie', 'self-love', 'body-positive']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273890</th>\n",
       "      <td>['pro-recovery', 'stay safe']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           restr_segments_25  mental health\n",
       "3784240  ['19', 'sad', 'lonely\\\\\\\\\\\\\\\\miserable\\\\\\\\\\\\\\\\']     1.0          \n",
       "5541049  ['depressed teen', '16']                             1.0          \n",
       "5592086  ['anxieties']                                        1.0          \n",
       "5897239  ['fitness', 'foodie', 'self-love', 'body-positive']  1.0          \n",
       "6273890  ['pro-recovery', 'stay safe']                        1.0          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "personal description/commentary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>restr_segments_25</th>\n",
       "      <th>personal description/commentary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3745083</th>\n",
       "      <td>['weird', 'non-binary', 'otaku', 'aires', 'pansexual', 'writer', 'gamer', 'avenged sevenfold fan\\', \"they, their, they\\'re']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254008</th>\n",
       "      <td>['also write fanfiction too']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3478993</th>\n",
       "      <td>['just a potato', 'crazy space potato']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675110</th>\n",
       "      <td>['stark depressiv', '19 jahre']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3402670</th>\n",
       "      <td>['13', 'i have an adorable cat', 'artist']</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    restr_segments_25  \\\n",
       "3745083  ['weird', 'non-binary', 'otaku', 'aires', 'pansexual', 'writer', 'gamer', 'avenged sevenfold fan\\', \"they, their, they\\'re']   \n",
       "1254008  ['also write fanfiction too']                                                                                                  \n",
       "3478993  ['just a potato', 'crazy space potato']                                                                                        \n",
       "4675110  ['stark depressiv', '19 jahre']                                                                                                \n",
       "3402670  ['13', 'i have an adorable cat', 'artist']                                                                                     \n",
       "\n",
       "         personal description/commentary  \n",
       "3745083  1.0                              \n",
       "1254008  1.0                              \n",
       "3478993  1.0                              \n",
       "4675110  1.0                              \n",
       "3402670  1.0                              "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "other/notes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "a must be greater than 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-59da36cd8546>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m          'relationship status', 'mental health', 'personal description/commentary', 'other/notes']:\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'restr_segments_25'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   3439\u001b[0m                              \"provide positive value.\")\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3441\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3442\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_copy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mmtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be greater than 0"
     ]
    }
   ],
   "source": [
    "# Sample from each column\n",
    "# for c in list(split[s].columns)[2:-1]:\n",
    "for c in ['non-English', 'age', 'name', 'location', 'interests', 'adult content',\n",
    "         'sexual orientation', 'gender', 'pronouns', 'fandoms', 'link to external content',\n",
    "         'occupation', 'personality type', 'astrological sign', 'ethnicity/nationality',\n",
    "         'relationship status', 'mental health', 'personal description/commentary', 'other/notes']:\n",
    "    print(c)\n",
    "    display(split[s][split[s][c]==1].sample(n=5).loc[:, ['restr_segments_25', c]])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for specific category values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tumblog_id', 'activity_time_epoch', 'tumblr_blog_name',\n",
      "       'tumblr_blog_title', 'tumblr_blog_description', 'tumblr_blog_url',\n",
      "       'tumblr_blog_theme', 'is_group_blog', 'is_primary', 'is_private',\n",
      "       'created_time_epoch', 'updated_time_epoch', 'timezone', 'language',\n",
      "       'blog_classifier', 'generated_date', 'parsed_blog_description'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5238440"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load blog descriptions\n",
    "descs = pd.read_pickle('/usr0/home/mamille2/tumblr/data/blog_descriptions_recent100.pkl')\n",
    "print(descs.columns)\n",
    "len(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1664\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parsed_blog_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>He/him/they/them|INTP|19|5w4|Pisces|My main blog full of spells, aesthetics, and all sorts of things. All are welcome.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3527</th>\n",
       "      <td>Esther. ENTP / Libra / 8w7 / Slytherin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10312</th>\n",
       "      <td>ISFJ | Hufflepuff | 2w3 22 | Taurus | USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10919</th>\n",
       "      <td>9w1 . INFP . 963   Ravenclaw/Wampus. Unconventional Capricorn.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18341</th>\n",
       "      <td>INFJ~4w3~Trying to find my place in this crazy, insane, messed-up, beautiful world. üåç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22331</th>\n",
       "      <td>hannah, taurus, infp, 4w5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24324</th>\n",
       "      <td>// You are likely to be eaten by a Grue  // Pop-surrealist // 4w5 // INT(F)J //  ‡≤†_‡≤†</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24871</th>\n",
       "      <td>INTP. 5w6, 9w8, 2w3. True Neutral. Melancholic/Phlegmatic. Medical Student.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30867</th>\n",
       "      <td>27(4/13)* 420Lover* StarWarsNerd* ChicagoBurbs* PetrolHead* HondaFanatic* INTP*6w5*Aries‚ôàsun* Sagittarius‚ôêmoon*Virgo‚ôçrising*Scorpio‚ôèlillith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67126</th>\n",
       "      <td>nat // 20 // entp // atl // 6w7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67604</th>\n",
       "      <td>INTP - 5w6 - Libra - Designer - Lone Wolf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77594</th>\n",
       "      <td>INFJü¶Ñ5w4 (529)üí°Elsa‚ùÑÔ∏è Artistüé®A bit nuts üí¨</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78125</th>\n",
       "      <td>I like Bikini Kill. 6w5 Melancholic INFP  Chaotic Good Katia/20/NM/NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80082</th>\n",
       "      <td>23. Christian. ISFJ. 6w7. A blog filled with quotes about my faith, pictures of nature, and gifs of my fandoms thrown in between.  Current Obsession : Critical Role</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80342</th>\n",
       "      <td>intj / 5w4 / observer /  my cognitive functionality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81714</th>\n",
       "      <td>Starter:Wonders of tumblr  Main course:MBTI stuff Dessert:Weird ideas  ENTP/7w8/so-sx My mother tongue is Turkish.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83092</th>\n",
       "      <td>22 || INFJ || 2w3 || She/her || Bi/Pan || Nerd. I never post anything and almost never reblog because of social anxiety. My only followers are the two people I know in real life and bots. There is probably nothing for you here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90623</th>\n",
       "      <td>|19| Alessia. Ex studentessa Liceo Artistico. Non lasciarti cambiare dagli altri, fai capire al mondo quanto sei speciale. ENFP 4w3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91212</th>\n",
       "      <td>20, she/they, demi, I dont tag my posts, dont reblog porn, just here to have a good time ENFP/Cancer/2w3 Equality for all, respect for all, and acceptance for all.  Talk to me if you want! I have lots of ocs, and I'm writing a book :)))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91471</th>\n",
       "      <td>Hi, I'm an INTJ, cisgender, secular ecclectic witch, and LGBT+ ally, nice to meet you. I never knew much of anything. Only now am I seeing more of my world. ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†...Ravenclaw...Gemini...The Dragon...The Scholar...Type One...Oak...Melancholic...6w5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102757</th>\n",
       "      <td>I'm Bree | 23 | INTP (6w5) | she/her.  Aspiring entomologist and animal lover. Mostly made of Radiohead and memes. ‚òÜ I have a bunch of side blogs.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105390</th>\n",
       "      <td>Hey! I'm Jennifer. 19. INFP 2w1, Gryffindor.¬†There is beauty in everything, if one should choose to look.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107730</th>\n",
       "      <td>I have thoughts and I put them here. 24. Danish-American. INFJ. 4w3. I'm a perpetual state of unintentional dichotomy.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109507</th>\n",
       "      <td>INFJ/IEI-Ni (and probably stuck in a Ni-Ti loop)6w5 4w5 1w9 so/sx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114270</th>\n",
       "      <td>old soul - INFP 4w5 Aquarius</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117831</th>\n",
       "      <td>midnight adventure awaits the insomniac teens  ‚Ä¢INFP 4w5‚Ä¢  MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120641</th>\n",
       "      <td>INFP. 4w5.  &amp;&amp; this is my art blog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123380</th>\n",
       "      <td>Bubbly ENTJ/P¬†5w9 here.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127217</th>\n",
       "      <td>John||‚ôâ||21||ENTP||3w2 9w8 5w6 Copious amounts of Pokemon, MBTI, and gayness.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147444</th>\n",
       "      <td>capricorn// ENFJ-T // 2w1-6w7-9w8 (269) sx // not really sure what I'm doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6175475</th>\n",
       "      <td>Exploring my ever-shifting identity (and generally being a huge nerd). 4w3-7w6-1w9 / ENFP-A / Lawful Good / Ravenclaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179441</th>\n",
       "      <td>let's play a game called \"which girl is my favourite\" pfp by @caffe-0w0 !!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6179743</th>\n",
       "      <td>(reblogs mostly)  Isfp 9w1-4w3-7w8 sp/so</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6183717</th>\n",
       "      <td>i succ, you succ, everyone succs 7w7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6184005</th>\n",
       "      <td>I'm Neon Discharge, Revenir, The Framework, Nordir, Zeon Force, and „Éç„Ç™NEDIS„É≥ÊîæÈõª. So many aliases, not enough time on my hands.... ENTP, 7w6. Psalm 149:3.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6193889</th>\n",
       "      <td>Mostly reblogs from a 4w5, INFJ, panda obsessed girl¬† ¬†‚òÜ*:.ÔΩ°.o(‚âß‚ñΩ‚â¶)o.ÔΩ°.:*‚òÜ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6199366</th>\n",
       "      <td>infj | 5w4 | ravenclaw | capricorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202760</th>\n",
       "      <td>| Aquarius | INTP | 5w4 | she&amp;her |</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215420</th>\n",
       "      <td>thoughtful introvert//psych nerd INTP//5w6//16yo//aquarius hungry to learn//i act smart but i‚Äôm actually dumb lol i like cats and classical music... also memes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215870</th>\n",
       "      <td>Sociology // Politics // Harry Potter // Doctor Who  // Sherlock // Makeup // Music // 9w1-4w5-5w6 so/sx  // Huffleclaw/Ravenpuff // New Girl // Bones // Archaeology // Jane Austen // INxP // Psychology // vinyl records</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6220500</th>\n",
       "      <td>2w3 | sx/sp | 19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225074</th>\n",
       "      <td>7w7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6227616</th>\n",
       "      <td>INTJ 5w6 | Just a place for me to post my thoughts, I am by no means a Myers Briggs Expert! | Asks are open!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6242758</th>\n",
       "      <td>as free as the ocean || dreamer || passionate about space, both outer and personal || intp || leo || 5w6 || playlists, quotes, crappy writing, and more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6251463</th>\n",
       "      <td>Biancchi~ ENFP // 7w6 or 2w3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6272874</th>\n",
       "      <td>14 y.o. INFP (4w5, 479, gemini) boi obsessed with MBTI, enneagram, politics, shitposting, anime and skapunk ;) Antifa | GNWP | ancom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6279429</th>\n",
       "      <td>aesthetic and skincare reblogs mosty sometimes advice or tips based on my own experiences and enneagram/mbti too  ‚ù§IxFP 9w1-4w3-5w4 sp/so‚ù§</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6280067</th>\n",
       "      <td>INTP|5w6 9w8 2w3|15|She/Her|Homosexual|Artist|Clown|Ravenclaw|Cartoon Enthusiast|Thespian|</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6287268</th>\n",
       "      <td>Hola 7w7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289781</th>\n",
       "      <td>ESFP | 4w3 | 417 | sp/so | Ravenclaw | I'm honestly not sure about my type lol.. but MBTI and Enneagram are life!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6289948</th>\n",
       "      <td>chelle // INTP 5w4 sx/sp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292061</th>\n",
       "      <td>Basic description attempt!  Let‚Äôs see‚Ä¶   Primary ontological philosophy: Nihilism  Mbti: INTP enneagram: 5w6 tritype: 145 Big Five: RIAOS  Main subjects of interest: evolutionary biology, philosophy, politics, psychology, and sociology  Age: 16 (in around a month I will be 17)  I have ADHD, horrible social skills, I am likely autistic, and I am a cisgender male.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6295485</th>\n",
       "      <td>-Drawing- -Photography- -INFJ- -Capricorn- -2w3- -Hufflepuff-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296029</th>\n",
       "      <td>blog of an italian intp, 5w6, neutral good, capricorn, ravenclaw and pukwudgie bitch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298012</th>\n",
       "      <td>Cacti are a pretty swell plant, I believe in it 0w0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6298406</th>\n",
       "      <td>Otto ~ 17 ~ Ireland ~ INTJ ~ 1w2/4w5/5w4 sp/sx ~ Ravenclaw/Horned Serpent ~ Chaotic Good ~ MelPhleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303011</th>\n",
       "      <td>A highly sensitves outlook on life             | INFP 4w5 HS muslim |</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6313831</th>\n",
       "      <td>hi, my name is owen. i'm a simple person. INTP | 9w8 | aries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6315975</th>\n",
       "      <td>INFP,4w3,Chaotic good,slytherpuff ,18,cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6319553</th>\n",
       "      <td>INTJ, 8w7, Genderfluid, Pansexual, Polyamorous, Single, High School Graduate. Name is Tiff. Still deciding on pronouns, just do female for now.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1664 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                              parsed_blog_description\n",
       "872      He/him/they/them|INTP|19|5w4|Pisces|My main blog full of spells, aesthetics, and all sorts of things. All are welcome.                                                                                                                                                                                                                                                      \n",
       "3527     Esther. ENTP / Libra / 8w7 / Slytherin                                                                                                                                                                                                                                                                                                                                      \n",
       "10312    ISFJ | Hufflepuff | 2w3 22 | Taurus | USA                                                                                                                                                                                                                                                                                                                                   \n",
       "10919    9w1 . INFP . 963   Ravenclaw/Wampus. Unconventional Capricorn.                                                                                                                                                                                                                                                                                                              \n",
       "18341    INFJ~4w3~Trying to find my place in this crazy, insane, messed-up, beautiful world. üåç                                                                                                                                                                                                                                                                                       \n",
       "22331    hannah, taurus, infp, 4w5                                                                                                                                                                                                                                                                                                                                                   \n",
       "24324    // You are likely to be eaten by a Grue  // Pop-surrealist // 4w5 // INT(F)J //  ‡≤†_‡≤†                                                                                                                                                                                                                                                                                        \n",
       "24871    INTP. 5w6, 9w8, 2w3. True Neutral. Melancholic/Phlegmatic. Medical Student.                                                                                                                                                                                                                                                                                                 \n",
       "30867    27(4/13)* 420Lover* StarWarsNerd* ChicagoBurbs* PetrolHead* HondaFanatic* INTP*6w5*Aries‚ôàsun* Sagittarius‚ôêmoon*Virgo‚ôçrising*Scorpio‚ôèlillith                                                                                                                                                                                                                                 \n",
       "67126    nat // 20 // entp // atl // 6w7                                                                                                                                                                                                                                                                                                                                             \n",
       "67604    INTP - 5w6 - Libra - Designer - Lone Wolf                                                                                                                                                                                                                                                                                                                                   \n",
       "77594    INFJü¶Ñ5w4 (529)üí°Elsa‚ùÑÔ∏è Artistüé®A bit nuts üí¨                                                                                                                                                                                                                                                                                                                                   \n",
       "78125    I like Bikini Kill. 6w5 Melancholic INFP  Chaotic Good Katia/20/NM/NYC                                                                                                                                                                                                                                                                                                      \n",
       "80082    23. Christian. ISFJ. 6w7. A blog filled with quotes about my faith, pictures of nature, and gifs of my fandoms thrown in between.  Current Obsession : Critical Role                                                                                                                                                                                                        \n",
       "80342    intj / 5w4 / observer /  my cognitive functionality                                                                                                                                                                                                                                                                                                                         \n",
       "81714    Starter:Wonders of tumblr  Main course:MBTI stuff Dessert:Weird ideas  ENTP/7w8/so-sx My mother tongue is Turkish.                                                                                                                                                                                                                                                          \n",
       "83092    22 || INFJ || 2w3 || She/her || Bi/Pan || Nerd. I never post anything and almost never reblog because of social anxiety. My only followers are the two people I know in real life and bots. There is probably nothing for you here.                                                                                                                                         \n",
       "90623    |19| Alessia. Ex studentessa Liceo Artistico. Non lasciarti cambiare dagli altri, fai capire al mondo quanto sei speciale. ENFP 4w3                                                                                                                                                                                                                                         \n",
       "91212    20, she/they, demi, I dont tag my posts, dont reblog porn, just here to have a good time ENFP/Cancer/2w3 Equality for all, respect for all, and acceptance for all.  Talk to me if you want! I have lots of ocs, and I'm writing a book :)))                                                                                                                                \n",
       "91471    Hi, I'm an INTJ, cisgender, secular ecclectic witch, and LGBT+ ally, nice to meet you. I never knew much of anything. Only now am I seeing more of my world. ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬† ¬†...Ravenclaw...Gemini...The Dragon...The Scholar...Type One...Oak...Melancholic...6w5...                                        \n",
       "102757   I'm Bree | 23 | INTP (6w5) | she/her.  Aspiring entomologist and animal lover. Mostly made of Radiohead and memes. ‚òÜ I have a bunch of side blogs.                                                                                                                                                                                                                          \n",
       "105390   Hey! I'm Jennifer. 19. INFP 2w1, Gryffindor.¬†There is beauty in everything, if one should choose to look.                                                                                                                                                                                                                                                                   \n",
       "107730   I have thoughts and I put them here. 24. Danish-American. INFJ. 4w3. I'm a perpetual state of unintentional dichotomy.                                                                                                                                                                                                                                                      \n",
       "109507   INFJ/IEI-Ni (and probably stuck in a Ni-Ti loop)6w5 4w5 1w9 so/sx                                                                                                                                                                                                                                                                                                           \n",
       "114270   old soul - INFP 4w5 Aquarius                                                                                                                                                                                                                                                                                                                                                \n",
       "117831   midnight adventure awaits the insomniac teens  ‚Ä¢INFP 4w5‚Ä¢  MI                                                                                                                                                                                                                                                                                                               \n",
       "120641   INFP. 4w5.  && this is my art blog                                                                                                                                                                                                                                                                                                                                          \n",
       "123380   Bubbly ENTJ/P¬†5w9 here.                                                                                                                                                                                                                                                                                                                                                     \n",
       "127217   John||‚ôâ||21||ENTP||3w2 9w8 5w6 Copious amounts of Pokemon, MBTI, and gayness.                                                                                                                                                                                                                                                                                               \n",
       "147444   capricorn// ENFJ-T // 2w1-6w7-9w8 (269) sx // not really sure what I'm doing                                                                                                                                                                                                                                                                                                \n",
       "...                                                                               ...                                                                                                                                                                                                                                                                                                \n",
       "6175475  Exploring my ever-shifting identity (and generally being a huge nerd). 4w3-7w6-1w9 / ENFP-A / Lawful Good / Ravenclaw                                                                                                                                                                                                                                                       \n",
       "6179441  let's play a game called \"which girl is my favourite\" pfp by @caffe-0w0 !!!                                                                                                                                                                                                                                                                                                 \n",
       "6179743  (reblogs mostly)  Isfp 9w1-4w3-7w8 sp/so                                                                                                                                                                                                                                                                                                                                    \n",
       "6183717  i succ, you succ, everyone succs 7w7                                                                                                                                                                                                                                                                                                                                        \n",
       "6184005  I'm Neon Discharge, Revenir, The Framework, Nordir, Zeon Force, and „Éç„Ç™NEDIS„É≥ÊîæÈõª. So many aliases, not enough time on my hands.... ENTP, 7w6. Psalm 149:3.                                                                                                                                                                                                                    \n",
       "6193889  Mostly reblogs from a 4w5, INFJ, panda obsessed girl¬† ¬†‚òÜ*:.ÔΩ°.o(‚âß‚ñΩ‚â¶)o.ÔΩ°.:*‚òÜ                                                                                                                                                                                                                                                                                                  \n",
       "6199366  infj | 5w4 | ravenclaw | capricorn                                                                                                                                                                                                                                                                                                                                          \n",
       "6202760  | Aquarius | INTP | 5w4 | she&her |                                                                                                                                                                                                                                                                                                                                         \n",
       "6215420  thoughtful introvert//psych nerd INTP//5w6//16yo//aquarius hungry to learn//i act smart but i‚Äôm actually dumb lol i like cats and classical music... also memes                                                                                                                                                                                                             \n",
       "6215870  Sociology // Politics // Harry Potter // Doctor Who  // Sherlock // Makeup // Music // 9w1-4w5-5w6 so/sx  // Huffleclaw/Ravenpuff // New Girl // Bones // Archaeology // Jane Austen // INxP // Psychology // vinyl records                                                                                                                                                 \n",
       "6220500  2w3 | sx/sp | 19                                                                                                                                                                                                                                                                                                                                                            \n",
       "6225074  7w7                                                                                                                                                                                                                                                                                                                                                                         \n",
       "6227616  INTJ 5w6 | Just a place for me to post my thoughts, I am by no means a Myers Briggs Expert! | Asks are open!                                                                                                                                                                                                                                                                \n",
       "6242758  as free as the ocean || dreamer || passionate about space, both outer and personal || intp || leo || 5w6 || playlists, quotes, crappy writing, and more                                                                                                                                                                                                                     \n",
       "6251463  Biancchi~ ENFP // 7w6 or 2w3                                                                                                                                                                                                                                                                                                                                                \n",
       "6272874  14 y.o. INFP (4w5, 479, gemini) boi obsessed with MBTI, enneagram, politics, shitposting, anime and skapunk ;) Antifa | GNWP | ancom                                                                                                                                                                                                                                        \n",
       "6279429  aesthetic and skincare reblogs mosty sometimes advice or tips based on my own experiences and enneagram/mbti too  ‚ù§IxFP 9w1-4w3-5w4 sp/so‚ù§                                                                                                                                                                                                                                  \n",
       "6280067  INTP|5w6 9w8 2w3|15|She/Her|Homosexual|Artist|Clown|Ravenclaw|Cartoon Enthusiast|Thespian|                                                                                                                                                                                                                                                                                  \n",
       "6287268  Hola 7w7                                                                                                                                                                                                                                                                                                                                                                    \n",
       "6289781  ESFP | 4w3 | 417 | sp/so | Ravenclaw | I'm honestly not sure about my type lol.. but MBTI and Enneagram are life!                                                                                                                                                                                                                                                           \n",
       "6289948  chelle // INTP 5w4 sx/sp                                                                                                                                                                                                                                                                                                                                                    \n",
       "6292061  Basic description attempt!  Let‚Äôs see‚Ä¶   Primary ontological philosophy: Nihilism  Mbti: INTP enneagram: 5w6 tritype: 145 Big Five: RIAOS  Main subjects of interest: evolutionary biology, philosophy, politics, psychology, and sociology  Age: 16 (in around a month I will be 17)  I have ADHD, horrible social skills, I am likely autistic, and I am a cisgender male.\n",
       "6295485  -Drawing- -Photography- -INFJ- -Capricorn- -2w3- -Hufflepuff-                                                                                                                                                                                                                                                                                                               \n",
       "6296029  blog of an italian intp, 5w6, neutral good, capricorn, ravenclaw and pukwudgie bitch                                                                                                                                                                                                                                                                                        \n",
       "6298012  Cacti are a pretty swell plant, I believe in it 0w0                                                                                                                                                                                                                                                                                                                         \n",
       "6298406  Otto ~ 17 ~ Ireland ~ INTJ ~ 1w2/4w5/5w4 sp/sx ~ Ravenclaw/Horned Serpent ~ Chaotic Good ~ MelPhleg                                                                                                                                                                                                                                                                         \n",
       "6303011  A highly sensitves outlook on life             | INFP 4w5 HS muslim |                                                                                                                                                                                                                                                                                                       \n",
       "6313831  hi, my name is owen. i'm a simple person. INTP | 9w8 | aries                                                                                                                                                                                                                                                                                                                \n",
       "6315975  INFP,4w3,Chaotic good,slytherpuff ,18,cancer                                                                                                                                                                                                                                                                                                                                \n",
       "6319553  INTJ, 8w7, Genderfluid, Pansexual, Polyamorous, Single, High School Graduate. Name is Tiff. Still deciding on pronouns, just do female for now.                                                                                                                                                                                                                             \n",
       "\n",
       "[1664 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search_term = r'bun\\W'\n",
    "# search_term = r'bun pronoun'\n",
    "# search_term = r'\\brl\\b'\n",
    "search_term = r'\\b[0-9]w[0-9]\\b'\n",
    "selected = descs[descs['parsed_blog_description'].map(lambda x: True if re.search(search_term,x) else False)]\n",
    "print(len(selected))\n",
    "selected.loc[:,['parsed_blog_description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word and character ngrams for identity category mention prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change CSV to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled data\n",
    "split = {'dev200': None}\n",
    "for s in split:\n",
    "    split[s] = pd.read_csv(f'/usr0/home/mamille2/tumblr/data/list_descriptions_{s}.csv', index_col=0)\n",
    "    print(split[s].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rm_punct(segments):\n",
    "    \"\"\" Return segments split on punctuation, punctuation removed \"\"\"\n",
    "    \n",
    "    new_segs = []\n",
    "    \n",
    "    for seg in segments:\n",
    "        new_seg = ' '.join(re.split(r'\\W', seg))\n",
    "        new_seg = re.sub(r'\\W', ' ', new_seg)\n",
    "        new_seg = re.sub(r'\\s+', ' ', new_seg).strip()\n",
    "        new_segs.append(new_seg)\n",
    "        \n",
    "    return new_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# String representation to list\n",
    "# split[s]['restr_segments_25'] = split[s]['restr_segments_25'].map(lambda x: x[2:-2].split(\"', '\"))\n",
    "split[s]['restr_segments_25'] = split[s]['restr_segments_25'].map(lambda x: ast.literal_eval(x))\n",
    "split[s]['restr_segments_25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split[s]['segments_25_nopunct'] = list(map(split_rm_punct, tqdm(split[s]['restr_segments_25'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaNs -> 0\n",
    "for c in ['gender', 'sexual orientation', 'pronouns']:\n",
    "    split[s][c] = split[s][c].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split[s]['sexuality/gender'] = [max(tup) for tup in zip(split[s]['sexual orientation'], split[s]['gender'], split[s]['pronouns'])]\n",
    "len(split[s][split[s]['sexuality/gender'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split[s].to_pickle(f'/usr0/home/mamille2/tumblr/data/list_descriptions_{s}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load labeled data\n",
    "split = {'train1000': None, 'dev200': None}\n",
    "for s in split:\n",
    "    split[s] = pd.read_pickle(f'/usr0/home/mamille2/tumblr/data/list_descriptions_{s}.pkl')\n",
    "    print(split[s].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unigrams and bag of character ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vec_dict = {'unigrams': TfidfVectorizer(), 'char 1-4grams': TfidfVectorizer(analyzer='char', ngram_range=(1,4))}\n",
    "clf_dict = {'NB': MultinomialNB(), 'SVM': svm.SVC()}\n",
    "outcome_classes = ['sexual orientation', 'pronouns', 'gender', 'sexuality/gender']\n",
    "bow = {s: {} for s in split}\n",
    "labels = {s: {} for s in split}\n",
    "outlines = []\n",
    "\n",
    "# Get features\n",
    "# Fit\n",
    "for vec_name in vec_dict:\n",
    "    data = [' '.join(segs) for segs in split['train1000']['segments_25_nopunct'].tolist()]\n",
    "    vec_dict[vec_name].fit(data)\n",
    "\n",
    "for s in split:\n",
    "    for vec_name, vec in vec_dict.items():\n",
    "        data = [' '.join(segs) for segs in split[s]['segments_25_nopunct'].tolist()]\n",
    "        bow[s][vec_name] = vec.transform(data)\n",
    "    \n",
    "    # Get labels\n",
    "    for l in outcome_classes:\n",
    "        labels[s][l] = split[s][l].values\n",
    "\n",
    "# Training\n",
    "for vec_name in vec_dict:\n",
    "    for l in outcome_classes:\n",
    "        for clf_name, clf in clf_dict.items():\n",
    "            clf.fit(bow['train1000'][vec_name], labels['train1000'][l])\n",
    "            \n",
    "            # Testing\n",
    "            for s in split:\n",
    "                preds = clf.predict(bow[s][vec_name])\n",
    "                pos = preds==1 # positive guesses\n",
    "                true_pos = labels[s][l]==1 # true positives\n",
    "                matches = sum([all(tup) for tup in zip(pos, true_pos)])\n",
    "                prec = f'{matches}/{sum(pos)} ({matches/sum(pos):.1%})'\n",
    "                rec = f'{matches}/{sum(true_pos)} ({matches/sum(true_pos):.1%})'\n",
    "            \n",
    "                outlines.append([vec_name, clf_name, s, l, prec, rec])\n",
    "        \n",
    "pd.DataFrame(outlines, columns=['features', 'classifier', 'dataset', 'predicted class', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ['‚Ä¢draw for life‚Ä¢', '‚Ä¢a student‚Ä¢', '‚Ä¢18‚Ä¢']\n",
    "split_rm_punct(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pattern matching for mentions of identity categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tumblog_id', 'restr_segments_25', 'non-English', 'age', 'name',\n",
      "       'personal description/commentary', 'location', 'interests',\n",
      "       'adult content', 'sexual orientation', 'pronouns', 'gender', 'fandoms',\n",
      "       'link to external content', 'occupation', 'astrological sign',\n",
      "       'personality type', 'ethnicity/nationality', 'relationship status',\n",
      "       'mental health', 'other/notes', 'segments_25_nopunct',\n",
      "       'sexuality/gender'],\n",
      "      dtype='object')\n",
      "Index(['tumblog_id', 'restr_segments_25', 'non-English', 'age', 'name',\n",
      "       'personal description/commentary', 'location', 'interests',\n",
      "       'adult content', 'sexual orientation', 'pronouns', 'gender', 'fandoms',\n",
      "       'link to external content', 'occupation', 'astrological sign',\n",
      "       'personality type', 'ethnicity/nationality', 'relationship status',\n",
      "       'mental health', 'other/notes', 'segments_25_nopunct',\n",
      "       'sexuality/gender'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Load labeled data\n",
    "split = {'train1000': None, 'dev200': None}\n",
    "for s in split:\n",
    "    split[s] = pd.read_pickle(f'/usr0/home/mamille2/tumblr/data/list_descriptions_{s}.pkl')\n",
    "    print(split[s].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n",
      "1035\n"
     ]
    }
   ],
   "source": [
    "# Load US states\n",
    "fpath = '/usr0/home/mamille2/tumblr/data/states.csv'\n",
    "states = [s.lower() for s in pd.read_csv(fpath)['State'].tolist()]\n",
    "\n",
    "# Load nationalities\n",
    "fpath = '/usr0/home/mamille2/tumblr/data/nationalities.txt'\n",
    "with open(fpath) as f:\n",
    "    nats = [nat.lower() for nat in f.read().splitlines() if (len(nat) > 3 and not nat in states)]\n",
    "    \n",
    "print(len(nats))\n",
    "\n",
    "# Load ethnicities\n",
    "fpath = '/usr0/home/mamille2/tumblr/data/ethnicities.txt'\n",
    "outlist = states + ['coast']\n",
    "with open(fpath) as f:\n",
    "    eths = [e.split()[0].lower() for e in f.read().splitlines() if (len(e.split()[0]) > 4 and not e.split()[0].lower() in outlist)]\n",
    "    \n",
    "print(len(eths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex patterns\n",
    "terms = {\n",
    "        'age': [r'(?:[^-+\\w]|^)([1-6]{1}[0-9]{1})[^-+0-9]|^([1-6]{1}[0-9]{1})$',\n",
    "               r'twelve',\n",
    "               r'thirteen',\n",
    "               r'fourteen',\n",
    "               r'fifteen',\n",
    "               r'sixteen',\n",
    "               r'seventeen',\n",
    "               r'eighteen',\n",
    "               r'nineteen',\n",
    "               r'twenty',\n",
    "               r'thirty',\n",
    "               r'forty',\n",
    "               r'fifty',\n",
    "               r'sixty'],\n",
    "#         'location': [],\n",
    "        'gender': [r'male\\b', r'female', \n",
    "                    r'trans', r'ftm', r'mtf', r'cis',\n",
    "                    r'girl\\b', r'boy\\b', r'\\bman\\b', r'guy\\b', r'woman', r'gu+rl', r'gii+rl',\n",
    "                    r'non-binary', r'nonbinary', r'nb', r'agender', r'neutrois',\n",
    "                    r'\\bmom\\b', r'\\bdad\\b', r'wife', r'husband', r'\\bbrother\\b', r'\\bson\\b', r'\\bsister\\b',\n",
    "                    r'bigender', r'lgbt'],\n",
    "        'sexual orientation': \n",
    "                     [r'gay', r'straight', r'lesbian', r'\\bhomo',\n",
    "                       r'bisexual', r'\\bbi\\b', r'pansexual', r'\\bpan\\b',\n",
    "                       r'lgbt', r'queer',\n",
    "                       r'\\bace\\b', r'\\basexual', r'aro-ace', r'aro/ace',\n",
    "                     ],\n",
    "         'pronouns': [\n",
    "             r'(?:\\W|\\b)she(?:\\W|\\b)', r'(?:\\W|\\b)her(?:\\W|\\b)',\n",
    "             r'(?:\\W|\\b)he(?:\\W|\\b)', r'(?:\\W|\\b)him(?:\\W|\\b)',\n",
    "             r'(?:\\W|\\b)they(?:\\W|\\b)', r'(?:\\W|\\b)them(?:\\W|\\b)',\n",
    "             r'pronouns'\n",
    "                ],\n",
    "        'personality type': [\n",
    "            r'(?:i|e|a)(?:s|n)(?:t|f)(?:j|p)',\n",
    "            r'introvert',\n",
    "            r'extrovert', \n",
    "            r'ambivert',\n",
    "            r'\\b[0-9]w[0-9]\\b',\n",
    "            ],\n",
    "        'ethnicity/nationality': [r'\\b{}\\b'.format(el) for el in eths + nats] + \n",
    "                [r'latino', r'latina', r'cubana', r'cubano', r'chilena', r'chileno', r'mexicano', r'mexicana',\n",
    "                r'palestinian'],\n",
    "        'relationship status': [\n",
    "            r'taken', r'married', r'single', r'engaged', r'husband', r'spouse', r'wife', r'newlywed',\n",
    "            r'in a rl', r'in rl', r'in a relationship',\n",
    "        ]\n",
    "}\n",
    "terms['sexuality/gender'] = terms['gender'] + terms['sexual orientation'] + terms['pronouns']\n",
    "\n",
    "excl_terms = {\n",
    "    'age': ['nsfw 18', '18 nsfw', '18 only', 'only 18'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine terms in regex\n",
    "terms_re = {}\n",
    "for cat in terms:\n",
    "    terms_re[cat] = r'|'.join(terms[cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_category(cat, segments):\n",
    "    ans = False\n",
    "    \n",
    "    if not isinstance(segments, list):\n",
    "        return ans\n",
    "    \n",
    "    ans = any(re.search(terms_re[cat], s) for s in segments)\n",
    "#     for c in terms[cat]:\n",
    "#         ans = any(re.search(c, s) for s in segments)\n",
    "#         if ans:\n",
    "#             break\n",
    "            \n",
    "    if cat in excl_terms:\n",
    "        for c in excl_terms[cat]:\n",
    "            if any(c in s for s in segments):\n",
    "                ans = False\n",
    "            \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8da290e1e38444fbc99e68285e6a27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "gender\n",
      "sexual orientation\n",
      "pronouns\n",
      "personality type\n",
      "ethnicity/nationality\n",
      "relationship status\n",
      "sexuality/gender\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>predicted class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train1000</td>\n",
       "      <td>age</td>\n",
       "      <td>266/313 (85.0%)</td>\n",
       "      <td>266/294 (90.5%)</td>\n",
       "      <td>0.876442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev200</td>\n",
       "      <td>age</td>\n",
       "      <td>46/61 (75.4%)</td>\n",
       "      <td>46/52 (88.5%)</td>\n",
       "      <td>0.814159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train1000</td>\n",
       "      <td>gender</td>\n",
       "      <td>55/64 (85.9%)</td>\n",
       "      <td>55/69 (79.7%)</td>\n",
       "      <td>0.827068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev200</td>\n",
       "      <td>gender</td>\n",
       "      <td>5/10 (50.0%)</td>\n",
       "      <td>5/6 (83.3%)</td>\n",
       "      <td>0.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train1000</td>\n",
       "      <td>sexual orientation</td>\n",
       "      <td>53/57 (93.0%)</td>\n",
       "      <td>53/57 (93.0%)</td>\n",
       "      <td>0.929825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dev200</td>\n",
       "      <td>sexual orientation</td>\n",
       "      <td>10/10 (100.0%)</td>\n",
       "      <td>10/10 (100.0%)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>train1000</td>\n",
       "      <td>pronouns</td>\n",
       "      <td>68/74 (91.9%)</td>\n",
       "      <td>68/68 (100.0%)</td>\n",
       "      <td>0.957746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dev200</td>\n",
       "      <td>pronouns</td>\n",
       "      <td>9/14 (64.3%)</td>\n",
       "      <td>9/9 (100.0%)</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train1000</td>\n",
       "      <td>personality type</td>\n",
       "      <td>18/23 (78.3%)</td>\n",
       "      <td>18/19 (94.7%)</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>dev200</td>\n",
       "      <td>personality type</td>\n",
       "      <td>2/4 (50.0%)</td>\n",
       "      <td>2/2 (100.0%)</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>train1000</td>\n",
       "      <td>ethnicity/nationality</td>\n",
       "      <td>28/42 (66.7%)</td>\n",
       "      <td>28/39 (71.8%)</td>\n",
       "      <td>0.691358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>dev200</td>\n",
       "      <td>ethnicity/nationality</td>\n",
       "      <td>4/7 (57.1%)</td>\n",
       "      <td>4/4 (100.0%)</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train1000</td>\n",
       "      <td>relationship status</td>\n",
       "      <td>14/17 (82.4%)</td>\n",
       "      <td>14/17 (82.4%)</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dev200</td>\n",
       "      <td>relationship status</td>\n",
       "      <td>2/2 (100.0%)</td>\n",
       "      <td>2/2 (100.0%)</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>train1000</td>\n",
       "      <td>sexuality/gender</td>\n",
       "      <td>151/167 (90.4%)</td>\n",
       "      <td>151/163 (92.6%)</td>\n",
       "      <td>0.915152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>dev200</td>\n",
       "      <td>sexuality/gender</td>\n",
       "      <td>21/29 (72.4%)</td>\n",
       "      <td>21/21 (100.0%)</td>\n",
       "      <td>0.840000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      dataset        predicted class        precision           recall  \\\n",
       "0   train1000                    age  266/313 (85.0%)  266/294 (90.5%)   \n",
       "1      dev200                    age    46/61 (75.4%)    46/52 (88.5%)   \n",
       "2   train1000                 gender    55/64 (85.9%)    55/69 (79.7%)   \n",
       "3      dev200                 gender     5/10 (50.0%)      5/6 (83.3%)   \n",
       "4   train1000     sexual orientation    53/57 (93.0%)    53/57 (93.0%)   \n",
       "5      dev200     sexual orientation   10/10 (100.0%)   10/10 (100.0%)   \n",
       "6   train1000               pronouns    68/74 (91.9%)   68/68 (100.0%)   \n",
       "7      dev200               pronouns     9/14 (64.3%)     9/9 (100.0%)   \n",
       "8   train1000       personality type    18/23 (78.3%)    18/19 (94.7%)   \n",
       "9      dev200       personality type      2/4 (50.0%)     2/2 (100.0%)   \n",
       "10  train1000  ethnicity/nationality    28/42 (66.7%)    28/39 (71.8%)   \n",
       "11     dev200  ethnicity/nationality      4/7 (57.1%)     4/4 (100.0%)   \n",
       "12  train1000    relationship status    14/17 (82.4%)    14/17 (82.4%)   \n",
       "13     dev200    relationship status     2/2 (100.0%)     2/2 (100.0%)   \n",
       "14  train1000       sexuality/gender  151/167 (90.4%)  151/163 (92.6%)   \n",
       "15     dev200       sexuality/gender    21/29 (72.4%)   21/21 (100.0%)   \n",
       "\n",
       "          f1  \n",
       "0   0.876442  \n",
       "1   0.814159  \n",
       "2   0.827068  \n",
       "3   0.625000  \n",
       "4   0.929825  \n",
       "5   1.000000  \n",
       "6   0.957746  \n",
       "7   0.782609  \n",
       "8   0.857143  \n",
       "9   0.666667  \n",
       "10  0.691358  \n",
       "11  0.727273  \n",
       "12  0.823529  \n",
       "13  1.000000  \n",
       "14  0.915152  \n",
       "15  0.840000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives = {}\n",
    "negatives = {}\n",
    "truecat = {}\n",
    "pos_matches = {}\n",
    "outlines = []\n",
    "\n",
    "for cat in tqdm(terms):\n",
    "    print(cat)\n",
    "    positives[cat] = {}\n",
    "    negatives[cat] = {}\n",
    "    truecat[cat] = {}\n",
    "    pos_matches[cat] = {}\n",
    "    \n",
    "    for sp in split:\n",
    "    \n",
    "        preds = []\n",
    "        preds = split[sp]['segments_25_nopunct'].map(lambda x: has_category(cat, x))\n",
    "\n",
    "        # Get precision and recall\n",
    "        positives[cat][sp] = preds[preds==True]\n",
    "        negatives[cat][sp] = preds[preds==False]\n",
    "        pos_matches[cat][sp] = set(positives[cat][sp].index).intersection(split[sp][split[sp][cat]==1].index)\n",
    "        truecat[cat][sp] = split[sp][split[sp][cat]==1]\n",
    "\n",
    "        if len(pos_matches[cat][sp]) > 0:\n",
    "            prec = len(pos_matches[cat][sp])/len(positives[cat][sp])\n",
    "        else:    \n",
    "            prec = 0\n",
    "            \n",
    "        prec_str = f'{len(pos_matches[cat][sp])}/{len(positives[cat][sp])} ({prec:.1%})'\n",
    "            \n",
    "        rec = len(pos_matches[cat][sp])/len(truecat[cat][sp])\n",
    "        rec_str = f'{len(pos_matches[cat][sp])}/{len(truecat[cat][sp])} ({rec:.1%})'\n",
    "        f1 = 2 * prec * rec / (prec + rec)\n",
    "\n",
    "        outlines.append([sp, cat, prec_str, rec_str, f1])\n",
    "    \n",
    "pd.DataFrame(outlines, columns=['dataset', 'predicted class', 'precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positives:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segments_25_nopunct</th>\n",
       "      <th>ethnicity/nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2085891</th>\n",
       "      <td>[madridista primero, luego mexicano]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3928996</th>\n",
       "      <td>[heo jongin sage xxiv, racer, kamikaze, black chevy corvette c5, ]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3027319</th>\n",
       "      <td>[english major, poet, hockey player, var fhs document, location var w_h window, screen, width x window, screen, height fhs, src s1, freehostedscripts, net ocounter, head, appendchild fhs document, src s1, freehostedscripts, net ocount, head]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337898</th>\n",
       "      <td>[female, 25, in a good working rl, german, filthy 18 only]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5701899</th>\n",
       "      <td>[14 years old, french, lunax lulu, cosplayer, do some random art]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416138</th>\n",
       "      <td>[owner male, 19 years old, panda white tiger, writer]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267373</th>\n",
       "      <td>[but probably bisexual, chinese zodiac horse, who knows, not me]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236218</th>\n",
       "      <td>[an american musical]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5182327</th>\n",
       "      <td>[27, lesbian, switch most submissive, nsfw r18 posts, speak english spanish]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620408</th>\n",
       "      <td>[lvl 18, green black, fma, otaku, , japan, snapchat lilja_elric]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034906</th>\n",
       "      <td>[radfem 18 desi american, poli sci major]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6128605</th>\n",
       "      <td>[big nigger nostrils, see that right there, has the white man scared]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309630</th>\n",
       "      <td>[it was in 1975 18 y, fran√ßais, english]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4297149</th>\n",
       "      <td>[17, july 4, i speak spanish english]</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                       segments_25_nopunct  \\\n",
       "2085891  [madridista primero, luego mexicano]                                                                                                                                                                                                                \n",
       "3928996  [heo jongin sage xxiv, racer, kamikaze, black chevy corvette c5, ]                                                                                                                                                                                  \n",
       "3027319  [english major, poet, hockey player, var fhs document, location var w_h window, screen, width x window, screen, height fhs, src s1, freehostedscripts, net ocounter, head, appendchild fhs document, src s1, freehostedscripts, net ocount, head]   \n",
       "2337898  [female, 25, in a good working rl, german, filthy 18 only]                                                                                                                                                                                          \n",
       "5701899  [14 years old, french, lunax lulu, cosplayer, do some random art]                                                                                                                                                                                   \n",
       "2416138  [owner male, 19 years old, panda white tiger, writer]                                                                                                                                                                                               \n",
       "3267373  [but probably bisexual, chinese zodiac horse, who knows, not me]                                                                                                                                                                                    \n",
       "3236218  [an american musical]                                                                                                                                                                                                                               \n",
       "5182327  [27, lesbian, switch most submissive, nsfw r18 posts, speak english spanish]                                                                                                                                                                        \n",
       "2620408  [lvl 18, green black, fma, otaku, , japan, snapchat lilja_elric]                                                                                                                                                                                    \n",
       "5034906  [radfem 18 desi american, poli sci major]                                                                                                                                                                                                           \n",
       "6128605  [big nigger nostrils, see that right there, has the white man scared]                                                                                                                                                                               \n",
       "6309630  [it was in 1975 18 y, fran√ßais, english]                                                                                                                                                                                                            \n",
       "4297149  [17, july 4, i speak spanish english]                                                                                                                                                                                                               \n",
       "\n",
       "         ethnicity/nationality  \n",
       "2085891 NaN                     \n",
       "3928996 NaN                     \n",
       "3027319 NaN                     \n",
       "2337898 NaN                     \n",
       "5701899 NaN                     \n",
       "2416138 NaN                     \n",
       "3267373 NaN                     \n",
       "3236218 NaN                     \n",
       "5182327 NaN                     \n",
       "2620408 NaN                     \n",
       "5034906 NaN                     \n",
       "6128605 NaN                     \n",
       "6309630 NaN                     \n",
       "4297149 NaN                     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False negatives:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segments_25_nopunct</th>\n",
       "      <th>ethnicity/nationality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1219397</th>\n",
       "      <td>[instagram pristinetrash, darian, , bi]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3320520</th>\n",
       "      <td>[ayla, 16, the netherlands]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2881000</th>\n",
       "      <td>[italy, female]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919978</th>\n",
       "      <td>[baby, brasil, mg]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780813</th>\n",
       "      <td>[allah swt]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191982</th>\n",
       "      <td>[andrea, 20, m√©xico]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188208</th>\n",
       "      <td>[makeup, 17, us]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31575</th>\n",
       "      <td>[twenty three, social justice advocate, lover of jesus people]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745368</th>\n",
       "      <td>[22, jesus follower, nature, coffee, traveler]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3112475</th>\n",
       "      <td>[bk, nyc bk]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689086</th>\n",
       "      <td>[, aspiring model, actor]</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    segments_25_nopunct  \\\n",
       "1219397  [instagram pristinetrash, darian, , bi]                          \n",
       "3320520  [ayla, 16, the netherlands]                                      \n",
       "2881000  [italy, female]                                                  \n",
       "3919978  [baby, brasil, mg]                                               \n",
       "1780813  [allah swt]                                                      \n",
       "2191982  [andrea, 20, m√©xico]                                             \n",
       "188208   [makeup, 17, us]                                                 \n",
       "31575    [twenty three, social justice advocate, lover of jesus people]   \n",
       "745368   [22, jesus follower, nature, coffee, traveler]                   \n",
       "3112475  [bk, nyc bk]                                                     \n",
       "689086   [, aspiring model, actor]                                        \n",
       "\n",
       "         ethnicity/nationality  \n",
       "1219397  1.0                    \n",
       "3320520  1.0                    \n",
       "2881000  1.0                    \n",
       "3919978  1.0                    \n",
       "1780813  1.0                    \n",
       "2191982  1.0                    \n",
       "188208   1.0                    \n",
       "31575    1.0                    \n",
       "745368   1.0                    \n",
       "3112475  1.0                    \n",
       "689086   1.0                    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Examine misclassified\n",
    "cat = 'ethnicity/nationality'\n",
    "sp = 'train1000'\n",
    "\n",
    "print('False positives:')\n",
    "false_positives = set(positives[cat][sp].index).intersection(split[sp][split[sp][cat]!=1].index)\n",
    "display(split[sp].loc[false_positives, ['segments_25_nopunct', cat]])\n",
    "\n",
    "print('False negatives:')\n",
    "false_negatives = set(negatives[cat][sp].index).intersection(split[sp][split[sp][cat]==1].index)\n",
    "display(split[sp].loc[false_negatives, ['segments_25_nopunct', cat]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "east coast\n",
      "coast\n"
     ]
    }
   ],
   "source": [
    "row = 6137916\n",
    "for term in split[sp].loc[row, 'segments_25_nopunct']:\n",
    "    for t in eths:\n",
    "        if re.search(t, term):\n",
    "            print(term)\n",
    "            print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cat in ['sexual orientation', 'gender', 'pronouns', 'sexuality/gender']:\n",
    "    print(cat)\n",
    "    print(has_category(cat, split['dev200'].loc[4539145, 'segments_25_nopunct']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply to corpus of descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['tumblog_id', 'activity_time_epoch', 'tumblr_blog_name',\n",
      "       'tumblr_blog_title', 'tumblr_blog_description', 'tumblr_blog_url',\n",
      "       'tumblr_blog_theme', 'is_group_blog', 'is_primary', 'is_private',\n",
      "       'created_time_epoch', 'updated_time_epoch', 'timezone', 'language',\n",
      "       'blog_classifier', 'generated_date', 'parsed_blog_description',\n",
      "       'segments', 'restr_segments_25'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1134175"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load blog descriptions\n",
    "descs = pd.read_pickle('/usr0/home/mamille2/tumblr/data/list_descriptions_recent100_restr25.pkl')\n",
    "print(descs.columns)\n",
    "len(descs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25efd09a6bc428b9fe34ee8a1445fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "gender\n",
      "sexual orientation\n",
      "pronouns\n",
      "personality type\n",
      "ethnicity/nationality\n",
      "relationship status\n",
      "sexuality/gender\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Annotate for identity categories\n",
    "for cat in tqdm(terms):\n",
    "    print(cat)\n",
    "    descs[cat] = descs['segments_25_nopunct'].map(lambda x: has_category(cat, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp = 'train500'\n",
    "# sp = 'dev100'\n",
    "incorrect = split[sp][split[sp]['restr_segments_25'].map(lambda x: 'aromantic' in ' '.join(x))]\n",
    "# incorrect = split[sp][split[sp]['restr_segments_25'].map(lambda x: 'poly' in ' '.join(x))]\n",
    "incorrect\n",
    "# mask = split['train500']['restr_segments_25'].map(lambda x: 'poly' in ' '.join(x) if isinstance(x, list))\n",
    "# split['train500'][mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrections\n",
    "sp = 'train500'\n",
    "cat = 'pronouns'\n",
    "val = 1\n",
    "# sp = 'dev100'\n",
    "\n",
    "# for i in incorrect.index:\n",
    "for i in [3047905]:\n",
    "    split[sp].loc[i, cat] = val\n",
    "    \n",
    "len(split[sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "split['train500']['gender'] = split['train500']['gender'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert from string to list\n",
    "split['dev100']['restr_segments_25'] = split['dev100']['restr_segments_25'].map(lambda x: x[2:-2].split(\"', '\") if isinstance(x, str) else x)\n",
    "split['dev100']['restr_segments_25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove mistake settings\n",
    "split['train500'] = split['train500'][split['train500']['restr_segments_25'].map(lambda x: not isinstance(x, float))]\n",
    "len(split['train500'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove mistake settings\n",
    "split['dev100'] = split['dev100'][split['dev100']['restr_segments_25'].map(lambda x: not isinstance(x, float))]\n",
    "len(split['dev100'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = {}\n",
    "s = 'train1000'\n",
    "split[s] = pd.read_csv(f'/usr0/home/mamille2/tumblr/data/list_descriptions_{s}.csv', index_col=0)\n",
    "len(split[s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert from string to list\n",
    "split[s]['restr_segments_25'] = split[s]['restr_segments_25'].map(lambda x: x[2:-2].split(\"', '\") if isinstance(x, str) else x)\n",
    "split[s]['restr_segments_25']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split[s].to_pickle(f'/usr0/home/mamille2/tumblr/data/list_descriptions_{s}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split['dev100'].to_pickle('/usr0/home/mamille2/tumblr/data/list_descriptions_dev100.pkl')\n",
    "split['dev100'].to_csv('/usr0/home/mamille2/tumblr/data/list_descriptions_dev100.csv')\n",
    "split['train500'].to_pickle('/usr0/home/mamille2/tumblr/data/list_descriptions_train500.pkl')\n",
    "split['train500'].to_csv('/usr0/home/mamille2/tumblr/data/list_descriptions_train500.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_rm_punct(segments):\n",
    "    \"\"\" Return segments split on punctuation, punctuation removed \"\"\"\n",
    "    \n",
    "    new_segs = []\n",
    "    \n",
    "    for seg in segments:\n",
    "        new_seg = ' '.join(re.split(r'\\W', seg))\n",
    "        new_seg = re.sub(r'\\W', ' ', new_seg)\n",
    "        new_seg = re.sub(r'\\s+', ' ', new_seg).strip()\n",
    "        new_segs.append(new_seg)\n",
    "        \n",
    "    return new_segs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c25acd87776492597c28df362443779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1134175), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "descs['segments_25_nopunct'] = list(map(split_rm_punct, tqdm(descs['restr_segments_25'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "descs.to_pickle('/usr0/home/mamille2/tumblr/data/list_descriptions_recent100_restr25.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "preds = split['dev200']['restr_segments_25'].map(lambda x: has_category('sexuality/gender', x))\n",
    "preds[preds==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split['dev200'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split['dev200'].rename(columns={'personal description/ commentary': 'personal description/commentary',\n",
    "                               'ethnicity/ nationality': 'ethnicity/nationality'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split['dev200'].to_pickle('/usr0/home/mamille2/tumblr/data/list_descriptions_dev200.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_category('sexuality/gender', split['dev200'].loc[4539145,'restr_segments_25'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_category('gender', ['male', '28'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_category('gender', ['girl', '28'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_category('sexual orientation', ['pan as fuck', '28'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_category('pronouns', ['she/her', 'them', 'he'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_category('pronouns', ['banshee'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "has_category('pronouns', ['he they'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitatively examine description segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load descriptions\n",
    "list_desc_data = pd.read_pickle('/usr0/home/mamille2/tumblr/data/list_descriptions.pkl')\n",
    "print(len(list_desc_data))\n",
    "print(list_desc_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "samp = list_desc_data.sample(30)\n",
    "samp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine Brown clustering of description segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/usr0/home/mamille2/brown-cluster/desc_segments_20-c50-p1.out/paths') as f:\n",
    "# with open('/usr0/home/mamille2/brown-cluster/desc_segments_20_freq-c50-p1.out/paths') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    \n",
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlines = []\n",
    "\n",
    "for l in lines:\n",
    "    l_split = l.split('\\t')\n",
    "    if len(l_split) == 3:\n",
    "        outlines.append(l_split)\n",
    "#         clu['all'][l_split[0]].append(l_split[1])\n",
    "    \n",
    "# print(len(clu['all']))\n",
    "# clu['all'].keys()\n",
    "\n",
    "clu = pd.DataFrame(outlines, columns=['cluster', 'word', 'freq'])\n",
    "clu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu['freq'] = clu['freq'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu.sort_values(['cluster', 'freq'], inplace=True, ascending=False)\n",
    "clu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val in clu['cluster'].unique():\n",
    "    rows = clu[clu['cluster']==val]\n",
    "    print(rows.head(20))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clu.to_csv('/usr0/home/mamille2/tumblr/results/desc_segments_brown_clusters.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce dimensionality of description embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desc_embs = np.load('/usr0/home/mamille2/tumblr/data/desc_recent5_embeddings_avg.npy')\n",
    "# desc_embs = np.load('/usr0/home/mamille2/tumblr/data/desc_embeddings_avg.npy')\n",
    "desc_embs = np.load('/usr0/home/mamille2/tumblr/data/desc_recent5_avg.npy')\n",
    "desc_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels (top prob clusters)--just load saved probabilities\n",
    "# probs = np.load('/usr0/home/mamille2/tumblr/data/gmm_50_desc_avg_probs.npy')\n",
    "# probs = np.load('/usr0/home/mamille2/tumblr/data/gmm_cotrain_50_desc_avg_probs.npy')\n",
    "probs = np.load('/usr0/home/mamille2/tumblr/data/recent5_gmm_50_desc_avg_probs.npy')\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_assgn = np.argsort(probs, axis=1)[:,-1] \n",
    "clusters_assgn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(desc_embs)\n",
    "print(reduced.shape)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensions to 50 first\n",
    "pca = PCA(n_components=50)\n",
    "pca_reduced = pca.fit_transform(desc_embs)\n",
    "print(pca_reduced.shape)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inds = np.random.choice(len(pca_reduced), int(1e4))\n",
    "samp = pca_reduced[inds]\n",
    "\n",
    "tsne = TSNE(n_components=2, verbose=2)\n",
    "# reduced = tsne.fit_transform(desc_embs)\n",
    "reduced = tsne.fit_transform(samp)\n",
    "print(reduced.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph clusters of reduced dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If sampled, need to same cluster assignments\n",
    "clusters_assgn = clusters_assgn[inds]\n",
    "len(clusters_assgn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "scatter = plt.scatter(reduced[:,0], reduced[:,1], c=clusters_assgn, s=10)\n",
    "plt.colorbar(scatter)\n",
    "# plt.axis([-1,2.5,-4,1.5])\n",
    "plt.axis([-3,10,-2,5])\n",
    "# plt.title(\"PCA of cotrained description embeddings\")\n",
    "plt.title(\"PCA of description embeddings\")\n",
    "# plt.title(\"t-SNE of description embeddings (10k)\")\n",
    "# fig.savefig('/usr0/home/mamille2/tumblr/results/pca_cotrain.png', dpi=100)\n",
    "fig.savefig('/usr0/home/mamille2/tumblr/results/pca_desc_recent5.png', dpi=100)\n",
    "# fig.savefig('/usr0/home/mamille2/tumblr/results/tsne_cotrain.png', dpi=100)\n",
    "# fig.savefig('/usr0/home/mamille2/tumblr/results/tsne_desc.png', dpi=100)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clu_ctr = Counter(clusters_assgn)\n",
    "clu_ctr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run GMM clustering on blog descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "desc_emb_path = '/usr0/home/mamille2/tumblr/data/desc_embeddings_avg.npy'\n",
    "desc_emb = np.load(desc_emb_path)\n",
    "desc_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = desc_emb[:500000,:]\n",
    "clf = GaussianMixture(n_components=50, verbose=2, warm_start=True)\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outpath = '/usr0/home/mamille2/tumblr/data/gmm_20_desc.pkl'\n",
    "\n",
    "with open(outpath, 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to continue training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# path = '/usr0/home/mamille2/tumblr/data/gmm_20_desc.pkl'\n",
    "path = '/usr0/home/mamille2/tumblr/data/gmm_50_desc.pkl'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = desc_emb[:500000,:]\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine trained GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# desc_emb_path = '/usr0/home/mamille2/tumblr/data/desc_embeddings_avg.npy'\n",
    "# desc_emb_path = '/usr0/home/mamille2/tumblr/data/desc_recent5_embeddings_avg.npy'\n",
    "desc_emb_path = '/usr0/home/mamille2/tumblr/data/desc_recent5_embeddings_sum.npy'\n",
    "desc_emb = np.load(desc_emb_path)\n",
    "desc_emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# path = '/usr0/home/mamille2/tumblr/data/gmm_20_desc.pkl'\n",
    "# path = '/usr0/home/mamille2/tumblr/data/gmm_50_desc.pkl'\n",
    "# path = '/usr0/home/mamille2/tumblr/data/gmm_cotrain_50_desc.pkl'\n",
    "path = '/usr0/home/mamille2/tumblr/data/gmm_cotrain_50_desc_sum.pkl'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load descriptions\n",
    "# path = '/usr0/home/mamille2/tumblr/data/en_blog_descriptions.pkl'\n",
    "path = '/usr0/home/mamille2/tumblr/data/desc_recent5.pkl'\n",
    "desc_df = pd.read_pickle(path)\n",
    "\n",
    "# descs = desc_df['parsed_blog_description'].tolist()\n",
    "desc_toks = desc_df['tokenized_blog_description'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.bic(desc_emb[:500000,:]) # -615M for 20 comps, -652M for 50 comps\n",
    "clf.bic(desc_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.lower_bound_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get highest weights\n",
    "wted_comps = np.argsort(clf.weights_)[::-1]\n",
    "wted_comps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine datapoints with highest probabilities assigned for each cluster; examine cluster assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probs = clf.predict_proba(desc_emb[:500000,:])\n",
    "probs = clf.predict_proba(desc_emb)\n",
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_probs = np.argsort(probs, axis=0)[::-1]\n",
    "top_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_descs(probs, descs, k, order, vocab_file=None):\n",
    "    \"\"\" Prints top k descriptions for each component\"\"\"\n",
    "    \n",
    "    top_probs = np.argsort(probs, axis=0)[::-1]\n",
    "    \n",
    "    if vocab_file: # dict [n_words]: [vocab]\n",
    "        with open(vocab_file, 'rb') as f:\n",
    "            vocab = pickle.load(f)\n",
    "    \n",
    "    for i in order:\n",
    "        print(\"Component {}\".format(i))\n",
    "        col = top_probs[:,i]\n",
    "#     for i, c in enumerate(top_probs.T):\n",
    "        \n",
    "        for el in col[:k]: \n",
    "            if vocab_file:\n",
    "                print('\\t' + ' '.join(d if d in vocab[100000] else '<unk>' for d in descs[el])) # for tokenized\n",
    "            else:\n",
    "                print('\\t' + ' '.join(d if d in vocab[100000] else '<unk>' for d in descs[el])) # for tokenized\n",
    "#             print('\\t' + descs[el])\n",
    "            \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top descriptions from halfday co-training, sum\n",
    "top_descs(probs, desc_toks, 20, wted_comps, '/usr0/home/mamille2/tumblr/data/halfday_top5_vocab100000.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top descriptions from just descriptions (50 components)\n",
    "top_descs(probs, descs, 20, wted_comps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top descriptions from halfday co-training, averages\n",
    "top_descs(probs, descs, 20, wted_comps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find closest words in embedding space to cluster means\n",
    "Doesn't really mean anything, as are averaging embeddings across all words in a post and 'dmitry' is closest to each cluster mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/usr0/home/mamille2/tumblr/data/desc_ftvecs100000.pkl'\n",
    "\n",
    "with open(path, 'rb') as f:\n",
    "    wd_embs = pickle.load(f)\n",
    "    \n",
    "len(wd_embs[100000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "closests = []\n",
    "dist = euclidean\n",
    "\n",
    "for m in tqdm(clf.means_):\n",
    "    closest_dist = np.infty\n",
    "    closest_wd = None\n",
    "    \n",
    "    for wd, emb in wd_embs[100000].items():\n",
    "        if dist(m,emb) < closest_dist:\n",
    "            closest_wd = wd\n",
    "            \n",
    "    closests.append(closest_wd)\n",
    "    \n",
    "closests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample blog descriptions for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# data = pd.read_csv('/usr0/home/mamille2/tumblr/data/en_nan_blog_descriptions.csv')\n",
    "data = pd.read_csv('/usr0/home/mamille2/tumblr/data/en_blog_descriptions.csv')\n",
    "print(len(data))\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = data.sample(n=10)\n",
    "s.loc[:, ['tumblog_id', 'tumblr_blog_name', 'tumblr_blog_title', 'tumblr_blog_url', 'timezone', 'tumblr_blog_description', 'parsed_blog_description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blog descriptions from blogs that have text posts in halfday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_posts = pd.read_pickle('/usr0/home/mamille2/tumblr/data/halfday_text.pkl')\n",
    "print(len(text_posts))\n",
    "text_posts.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blogs that also have text descriptions\n",
    "tumblogs_allposts = text_posts['tumblog_id'].unique()\n",
    "len(tumblogs_allposts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_series = text_posts.groupby(['tumblog_id']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tumblogs_2posts = count_series[count_series >= 2].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tumblogs_5posts = count_series[count_series >= 5].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tumblogs_10posts = count_series[count_series >= 10].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data[data['tumblog_id'].isin(tumblogs_allposts)]\n",
    "len(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text2 = data[data['tumblog_id'].isin(tumblogs_2posts)]\n",
    "len(data_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = data[data['tumblog_id'].isin(tumblogs_5posts)]\n",
    "len(data_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text10 = data[data['tumblog_id'].isin(tumblogs_10posts)]\n",
    "len(data_text10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample from those who have at least 10 text posts in halfday\n",
    "\n",
    "s = data_text10.sample(n=10)\n",
    "s.loc[:, ['tumblog_id', 'tumblr_blog_name', 'tumblr_blog_title', 'tumblr_blog_url', 'timezone', 'tumblr_blog_description', 'parsed_blog_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample from those who have at least 2 text posts in halfday\n",
    "\n",
    "s = data_text2.sample(n=10)\n",
    "s.loc[:, ['tumblog_id', 'tumblr_blog_name', 'tumblr_blog_title', 'tumblr_blog_url', 'timezone', 'tumblr_blog_description', 'parsed_blog_description']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA on blog descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get blog descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# data = pd.read_csv('/usr0/home/mamille2/tumblr/data/en_nan_blog_descriptions.csv')\n",
    "data = pd.read_csv('/usr0/home/mamille2/tumblr/data/en_blog_descriptions.csv')\n",
    "print(len(data))\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blog_descs = data['parsed_blog_description'].values\n",
    "blog_descs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tfidf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=100000)\n",
    "tfidf_mat = tfidf.fit_transform(blog_descs)\n",
    "tfidf_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=300)\n",
    "svd_mat = svd.fit_transform(tfidf_mat)\n",
    "svd_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd.explained_variance_ratio_.sum() \n",
    "# 17% with 100 components over full vocab \n",
    "# 22% with 100 components over top 100k words\n",
    "# 34% with 300 components over top 100k words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Words x components matrix\n",
    "svd.components_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word features\n",
    "feats = tfidf.get_feature_names()\n",
    "len(feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ranked word features by component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = np.argsort(svd.components_)[:100]\n",
    "top.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sub = top[:, :100]\n",
    "top_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats2names = np.vectorize(lambda x: feats[x])\n",
    "top_feats = feats2names(top_sub)\n",
    "top_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, factor in enumerate(top_feats):\n",
    "    print('Factor {}'.format(i))\n",
    "    pprint(factor)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/usr0/home/mamille2/tumblr/data/lsa_descriptions_topwords.npy', top_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ranked documents by component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_docs_idx = np.argsort(svd_mat.T) # Select 10 highest components\n",
    "top_docs_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_docs_idx = top_docs_idx[:100]\n",
    "top_docs_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_sub = top_docs_idx[:, :100]\n",
    "top_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2docs = np.vectorize(lambda x: blog_descs[x])\n",
    "top_docs = idx2docs(top_sub)\n",
    "top_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, factor in enumerate(top_docs):\n",
    "    print('Factor {}'.format(i))\n",
    "    pprint(factor)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_docs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-63329bfdf1e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/usr0/home/mamille2/tumblr/data/lsa_descriptions_topdocs.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'top_docs' is not defined"
     ]
    }
   ],
   "source": [
    "np.save('/usr0/home/mamille2/tumblr/data/lsa_descriptions_topdocs.npy', top_docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
